{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-LHRc9DTr8b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import six\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "import argparse\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import random\n",
        "import torch.distributions as D\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import shutil\n",
        "from argparse import Namespace\n",
        "import matplotlib.pyplot as plt\n",
        "import numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irEvw9iHTr8c"
      },
      "outputs": [],
      "source": [
        "__all__ = ['hparam_parser', 'hparams']\n",
        "\n",
        "\n",
        "\n",
        "def hparam_parser():\n",
        "    parser = argparse.ArgumentParser(add_help=False)\n",
        "    group = parser.add_argument_group('hyperparameters')\n",
        "\n",
        "    # architecture params\n",
        "    group.add_argument('--max_seq_len', type=int, default=250)\n",
        "    group.add_argument('--enc_model', type=str, default='lstm') #\n",
        "    group.add_argument('--dec_model', type=str, default='layer_norm')\n",
        "    group.add_argument('--enc_rnn_size', type=int, default=256)\n",
        "    group.add_argument('--dec_rnn_size', type=int, default=512)\n",
        "    group.add_argument('--z_size', type=int, default=128)\n",
        "    group.add_argument('--num_mixture', type=int, default=20)\n",
        "    group.add_argument('--r_dropout', type=float, default=0.1)\n",
        "    #group.add_argument('--input_dropout', type=float, default=0.0) # Not recommended\n",
        "    #group.add_argument('--output_dropout', type=float, default=0.0) # Not recommended\n",
        "\n",
        "    # loss params\n",
        "    group.add_argument('--kl_weight', type=float, default=0.5)\n",
        "    group.add_argument('--kl_weight_start', type=float, default=0.01) # eta_min\n",
        "    group.add_argument('--kl_tolerance', type=float, default=0.2) # kl_min\n",
        "    group.add_argument('--kl_decay_rate', type=float, default=0.99995) # R\n",
        "    group.add_argument('--reg_covar', type=float, default=1e-6) # covariance shrinkage\n",
        "\n",
        "    # training params\n",
        "    group.add_argument('--batch_size', type=int, default=100)\n",
        "    group.add_argument('--lr', type=float, default=0.001)\n",
        "    group.add_argument('--lr_decay', type=float, default=0.9999)\n",
        "    group.add_argument('--min_lr', type=float, default=0.00001) # UNUSED\n",
        "    group.add_argument('--grad_clip', type=float, default=1.0)\n",
        "\n",
        "    # dataset & data augmentation params\n",
        "    group.add_argument('--data_set', type=str, default=['cat.npz','car.npz'])\n",
        "    group.add_argument('--random_scale_factor', type=float, default=0.15)\n",
        "    group.add_argument('--augment_stroke_prob', type=float, default=0.10)\n",
        "    group.add_argument('--data_dir', type=str, default='data')\n",
        "    group.add_argument('--save_dir', type=str, default='results')\n",
        "    group.add_argument('--num_epochs',type=int,default=30)\n",
        "    group.add_argument('--num_workers',type=int,default=0)\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "def hparams(**kwargs):\n",
        "    parser = hparam_parser()\n",
        "    hps = parser.parse_args([])\n",
        "    for key,val in kwargs.items():\n",
        "        if not hasattr(hps, key):\n",
        "            warnings.warn(\"A non-standard hyperparam '%s' was specified.\" % key)\n",
        "        setattr(hps, key, val)\n",
        "    return hps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEqotogeTr8c"
      },
      "outputs": [],
      "source": [
        "def get_max_len(strokes):\n",
        "    \"\"\"Return the maximum length of an array of strokes.\"\"\"\n",
        "    max_len = 0\n",
        "    for stroke in strokes:\n",
        "        ml = len(stroke)\n",
        "        if ml > max_len:\n",
        "            max_len = ml\n",
        "    return max_len\n",
        "\n",
        "def to_tensor(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        pass\n",
        "    elif isinstance(x, np.ndarray):\n",
        "        x = torch.from_numpy(x)\n",
        "    else:\n",
        "        raise Exception('input must be a tensor or ndarray.')\n",
        "    return x.float()\n",
        "\n",
        "__all__ = ['load_strokes', 'SketchRNNDataset', 'collate_drawings']\n",
        "\n",
        "# start-of-sequence token\n",
        "SOS = torch.tensor([0, 0, 1, 0, 0], dtype=torch.float)\n",
        "\n",
        "\n",
        "def load_strokes(data_dir, hps):\n",
        "    \"\"\"Loads the .npz file, and splits the set into train/valid/test.\"\"\"\n",
        "\n",
        "    # normalizes the x and y columns using the training set.\n",
        "    # applies same scaling factor to valid and test set.\n",
        "\n",
        "    if isinstance(hps.data_set, list):\n",
        "        datasets = hps.data_set\n",
        "    else:\n",
        "        datasets = [hps.data_set]\n",
        "\n",
        "    train_strokes = None\n",
        "    valid_strokes = None\n",
        "    test_strokes = None\n",
        "\n",
        "    for dataset in datasets:\n",
        "        # First check if file exists locally\n",
        "        local_filepath = os.path.join(data_dir, dataset)\n",
        "\n",
        "        if os.path.exists(local_filepath):\n",
        "            print(f'Loading local file: {local_filepath}')\n",
        "            data = np.load(local_filepath, encoding='latin1', allow_pickle=True)\n",
        "        else:\n",
        "            # If not local, try downloading from Google Cloud Storage\n",
        "            base_url = 'https://storage.googleapis.com/quickdraw_dataset/sketchrnn/'\n",
        "            data_filepath = base_url + dataset\n",
        "            print('Downloading %s' % data_filepath)\n",
        "\n",
        "            try:\n",
        "                response = requests.get(data_filepath)\n",
        "                response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "                # Ensure data_dir exists before saving\n",
        "                os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "                # Save the downloaded file\n",
        "                with open(local_filepath, 'wb') as f:\n",
        "                    f.write(response.content)\n",
        "\n",
        "                # Load the saved file with pickle support\n",
        "                data = np.load(local_filepath, encoding='latin1', allow_pickle=True)\n",
        "                print(f'Downloaded and saved {dataset} to {local_filepath}')\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {dataset}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print('Loaded {}/{}/{} from {}'.format(\n",
        "            len(data['train']), len(data['valid']), len(data['test']), dataset))\n",
        "\n",
        "        if train_strokes is None:\n",
        "            train_strokes = data['train']\n",
        "            valid_strokes = data['valid']\n",
        "            test_strokes = data['test']\n",
        "        else:\n",
        "            train_strokes = np.concatenate((train_strokes, data['train']))\n",
        "            valid_strokes = np.concatenate((valid_strokes, data['valid']))\n",
        "            test_strokes = np.concatenate((test_strokes, data['test']))\n",
        "\n",
        "    all_strokes = np.concatenate((train_strokes, valid_strokes, test_strokes))\n",
        "    num_points = 0\n",
        "    for stroke in all_strokes:\n",
        "        num_points += len(stroke)\n",
        "    avg_len = num_points / len(all_strokes)\n",
        "    print('Dataset combined: {} ({}/{}/{}), avg len {}'.format(\n",
        "        len(all_strokes), len(train_strokes), len(valid_strokes),\n",
        "        len(test_strokes), int(avg_len)))\n",
        "\n",
        "    # calculate the max stroke len and overwrite hps\n",
        "    hps.max_seq_len = get_max_len(all_strokes)\n",
        "    print('hps.max_seq_len %i.' % hps.max_seq_len)\n",
        "\n",
        "    return train_strokes, valid_strokes, test_strokes\n",
        "\n",
        "\n",
        "class SketchRNNDataset:\n",
        "    def __init__(self,\n",
        "                 strokes,\n",
        "                 max_len=250,\n",
        "                 scale_factor=None,\n",
        "                 random_scale_factor=0.0,\n",
        "                 augment_stroke_prob=0.0,\n",
        "                 limit=1000):\n",
        "        strokes = [to_tensor(stk) for stk in strokes]\n",
        "        self.max_len = max_len  # N_max in sketch-rnn paper\n",
        "        self.random_scale_factor = random_scale_factor  # data augmentation method\n",
        "        self.augment_stroke_prob = augment_stroke_prob  # data augmentation method\n",
        "        self.limit = limit # clamp x-y offsets to range (-limit, limit)\n",
        "        self.preprocess(strokes) # list of drawings in stroke-3 format, sorted by size\n",
        "        self.normalize(scale_factor)\n",
        "\n",
        "    def preprocess(self, strokes):\n",
        "        \"\"\"Remove entries from strokes having > max_len points.\n",
        "        Clamp x-y values to (-limit, limit)\n",
        "        \"\"\"\n",
        "        raw_data = []\n",
        "        seq_len = []\n",
        "        count_data = 0\n",
        "        for i in range(len(strokes)):\n",
        "            data = strokes[i]\n",
        "            if len(data) <= (self.max_len):\n",
        "                count_data += 1\n",
        "                data = data.clamp(-self.limit, self.limit)\n",
        "                raw_data.append(data)\n",
        "                seq_len.append(len(data))\n",
        "        self.sort_idx = np.argsort(seq_len)\n",
        "        self.strokes = [raw_data[ix] for ix in self.sort_idx]\n",
        "        print(\"total drawings <= max_seq_len is %d\" % count_data)\n",
        "\n",
        "    def calculate_normalizing_scale_factor(self):\n",
        "        \"\"\"Calculate the normalizing factor explained in appendix of sketch-rnn.\"\"\"\n",
        "        strokes = [elt for elt in self.strokes if len(elt) <= self.max_len]\n",
        "        data = torch.cat(strokes)\n",
        "        return data[:,:2].std()\n",
        "\n",
        "    def normalize(self, scale_factor=None):\n",
        "        \"\"\"Normalize entire dataset (delta_x, delta_y) by the scaling factor.\"\"\"\n",
        "        if scale_factor is None:\n",
        "            scale_factor = self.calculate_normalizing_scale_factor()\n",
        "        self.scale_factor = scale_factor\n",
        "        for i in range(len(self.strokes)):\n",
        "            self.strokes[i][:,:2] /= self.scale_factor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.strokes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.strokes[idx]\n",
        "        if self.random_scale_factor > 0:\n",
        "            data = random_scale(data, self.random_scale_factor)\n",
        "        if self.augment_stroke_prob > 0:\n",
        "            data = random_augment(data, self.augment_stroke_prob)\n",
        "        return data\n",
        "\n",
        "\n",
        "def random_scale(data, factor):\n",
        "    \"\"\"Augment data by stretching x and y axis randomly [1-e, 1+e].\"\"\"\n",
        "    data = data.clone()\n",
        "    x_scale = (torch.rand(()) - 0.5) * 2 * factor + 1.0\n",
        "    y_scale = (torch.rand(()) - 0.5) * 2 * factor + 1.0\n",
        "    data[:,0] *= x_scale\n",
        "    data[:,1] *= y_scale\n",
        "    return data\n",
        "\n",
        "def random_augment(data, prob):\n",
        "    \"\"\"Perform data augmentation by randomly dropping out strokes.\"\"\"\n",
        "    # drop each point within a line segments with a probability of prob\n",
        "    # note that the logic in the loop prevents points at the ends to be dropped.\n",
        "    data = data.clone()\n",
        "    result = []\n",
        "    prev_stroke = [0, 0, 1]\n",
        "    count = 0\n",
        "    stroke = [0, 0, 1]  # Added to be safe.\n",
        "    for i in range(len(data)):\n",
        "        candidate = [data[i][0], data[i][1], data[i][2]]\n",
        "        if candidate[2] == 1 or prev_stroke[2] == 1:\n",
        "            count = 0\n",
        "        else:\n",
        "            count += 1\n",
        "        check = candidate[2] == 0 and prev_stroke[2] == 0 and count > 2\n",
        "        if check and (torch.rand(()) < prob):\n",
        "            stroke[0] += candidate[0]\n",
        "            stroke[1] += candidate[1]\n",
        "        else:\n",
        "            stroke = candidate\n",
        "            prev_stroke = stroke\n",
        "            result.append(stroke)\n",
        "    result = torch.tensor(result, dtype=torch.float)\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "# ---- methods for batch collation ----\n",
        "\n",
        "def pad_batch(sequences, max_len):\n",
        "    \"\"\"Pad the batch to be stroke-5 bigger format as described in paper.\"\"\"\n",
        "    batch_size = len(sequences)\n",
        "    output = torch.zeros(batch_size, max_len+1, 5)\n",
        "    for i in range(batch_size):\n",
        "        seq, out = sequences[i], output[i]\n",
        "        l = len(seq)\n",
        "        assert l <= max_len\n",
        "        # fill sos value\n",
        "        out[0] = SOS\n",
        "        # fill remaining values\n",
        "        out = out[1:]\n",
        "        out[:l,:2] = seq[:,:2]\n",
        "        out[:l,3] = seq[:,2]\n",
        "        out[:l,2] = 1 - out[:l,3]\n",
        "        out[l:,4] = 1\n",
        "    return output\n",
        "\n",
        "def collate_drawings(sequences, max_len):\n",
        "    lengths = torch.tensor([len(seq) for seq in sequences],\n",
        "                           dtype=torch.long)\n",
        "    batch = pad_batch(sequences, max_len)\n",
        "    return batch, lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJZYbBkRTr8d"
      },
      "outputs": [],
      "source": [
        "__all__ = ['tikhonov_reg2d', 'compute_cov2d', 'sample_gmm']\n",
        "\n",
        "def tikhonov_reg2d(scales, corrs, alpha):\n",
        "    \"\"\"Adds a non-negative constant to the diagonal of the covariance\n",
        "    matrix for a 2D multivariate normal (\"tikhonov regularization\").\n",
        "    \"\"\"\n",
        "    scales_ = torch.sqrt(scales**2 + alpha)\n",
        "    corrs_ = corrs * torch.prod(scales, -1) / torch.prod(scales_, -1)\n",
        "    return scales_, corrs_\n",
        "\n",
        "def compute_cov2d(scales, corrs):\n",
        "    \"\"\"\n",
        "    Compute covariance matrix for 2D multivariate normal\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    scales: Tensor[...,d]\n",
        "    corrs: Tensor[...]\n",
        "    \"\"\"\n",
        "    # compute covariances\n",
        "    cov12 = corrs*torch.prod(scales,dim=-1) # (...,)\n",
        "    covs = torch.diag_embed(scales**2) # (...,d,d)\n",
        "    I = torch.diag_embed(torch.ones_like(scales)) # (...,d,d)\n",
        "    covs = covs + cov12.unsqueeze(-1).unsqueeze(-1)*(1.-I)\n",
        "    return covs\n",
        "\n",
        "\n",
        "def sample_gmm(mix_logp, means, scales, corrs):\n",
        "    covs = compute_cov2d(scales, corrs)\n",
        "    mix = D.Categorical(mix_logp.exp())\n",
        "    comp = D.MultivariateNormal(means, covs)\n",
        "    gmm = D.MixtureSameFamily(mix, comp)\n",
        "    return gmm.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHoVpYbQTr8d"
      },
      "outputs": [],
      "source": [
        "__all__ = ['KLLoss', 'DrawingLoss']\n",
        "\n",
        "# ---- KL Divergence loss ----\n",
        "\n",
        "def kl_divergence_sn_prior(q_mean, q_logvar):\n",
        "    \"\"\"KL with standard normal prior (default)\"\"\"\n",
        "    kl = -0.5 * (1 + q_logvar - q_mean ** 2 - torch.exp(q_logvar))\n",
        "    return kl.mean()\n",
        "\n",
        "def kl_divergence(q_mean, q_logvar, p_mean=None, p_logvar=None):\n",
        "    if p_mean is None and p_logvar is None:\n",
        "        return kl_divergence_sn_prior(q_mean, q_logvar)\n",
        "    if p_mean is None: p_mean = torch.zeros_like(q_mean)\n",
        "    if p_logvar is None: p_logvar = torch.zeros_like(q_logvar)\n",
        "    kl = p_logvar - q_logvar + \\\n",
        "        (q_logvar.exp() + (q_mean - p_mean)**2) / p_logvar.exp() - 1\n",
        "    kl = 0.5 * kl\n",
        "    return kl.mean()\n",
        "\n",
        "class KLLoss(nn.Module):\n",
        "    def __init__(self, kl_weight=1., eta_min=0.01, R=0.99995, kl_min=0.):\n",
        "        super().__init__()\n",
        "        self.kl_weight = kl_weight\n",
        "        self.eta_min = eta_min\n",
        "        self.R = R\n",
        "        self.kl_min = kl_min\n",
        "        self.register_buffer('factor', torch.tensor(1-eta_min, dtype=torch.float))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.factor.fill_(1-self.eta_min)\n",
        "\n",
        "    @property\n",
        "    def weight(self):\n",
        "        eta = 1. - self.factor.item()\n",
        "        weight = self.kl_weight * eta\n",
        "        if self.training:\n",
        "            self.factor.mul_(self.R)\n",
        "        return weight\n",
        "\n",
        "    def forward(self, q_mean, q_logvar, p_mean=None, p_logvar=None):\n",
        "        if self.kl_weight == 0:\n",
        "            return torch.tensor(0., device=q_mean.device)\n",
        "        loss = kl_divergence(q_mean, q_logvar, p_mean, p_logvar)\n",
        "        loss = loss.clamp(self.kl_min, float('inf'))\n",
        "        loss = self.weight * loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "# ---- GMM Loss ----\n",
        "\n",
        "def mvn_log_prob(x, means, scales, corrs):\n",
        "    diff = (x.unsqueeze(-2) - means) / scales # [...,k,d]\n",
        "    z1 = diff.square().sum(-1) # [...,k]\n",
        "    z2 = 2 * corrs * diff.prod(-1) # [...,k]\n",
        "    logp1 = - 0.5 * (z1-z2) / (1-corrs**2) # [...,k]\n",
        "    logp2 = - 0.5 * (1-corrs**2).log() - scales.log().sum(-1) - math.log(2*math.pi)  # [...,k]\n",
        "    logp = logp1 + logp2 # [...,k]\n",
        "    return logp\n",
        "\n",
        "class DrawingLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reg_covar : float\n",
        "        Non-negative regularization added to the diagonal of covariance.\n",
        "    \"\"\"\n",
        "    def __init__(self, reg_covar=1e-6):\n",
        "        super().__init__()\n",
        "        self.reg_covar = reg_covar\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, v, params):\n",
        "        # unpack predicted parameters\n",
        "        mix_logp, means, scales, corrs, v_logp = params\n",
        "        if self.reg_covar > 0:\n",
        "            scales, corrs = tikhonov_reg2d(scales, corrs, alpha=self.reg_covar)\n",
        "        # losses_x: loss wrt pen offset (L_s in equation 9)\n",
        "        mvn_logp = mvn_log_prob(x, means, scales, corrs) # [batch,step,mix] //multi-variate normal log prob\n",
        "        gmm_logp = torch.logsumexp(mix_logp + mvn_logp, dim=-1) # [batch,step]\n",
        "        losses_x = -gmm_logp\n",
        "        # losses_v: loss wrt pen state (L_p in equation 9)\n",
        "        losses_v = F.nll_loss(v_logp.flatten(0,1), v.flatten(), reduction='none')\n",
        "        losses_v = losses_v.reshape(v.shape) # [batch,step]\n",
        "        # total average loss\n",
        "        # padding is masked always for x and only in eval mode for v\n",
        "        loss_x = losses_x[v!=2].mean()\n",
        "        loss_v = losses_v.mean() if self.training else losses_v[v!=2].mean()\n",
        "        loss = loss_x + loss_v\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W99ycGK3Tr8d"
      },
      "outputs": [],
      "source": [
        "__all__ = ['ParameterLayer']\n",
        "\n",
        "\n",
        "class ParameterLayer(nn.Module):\n",
        "    def __init__(self, input_size, k, d=2):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, k + 2*k*d + k + 3)\n",
        "        self.splits = [k, k*d, k*d, k, 3]\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.linear.reset_parameters()\n",
        "\n",
        "    def forward(self, x, T=1):\n",
        "        # linear forward\n",
        "        x = self.linear(x)\n",
        "\n",
        "        # unpack variables & apply activation\n",
        "        mix_logits, means, scales, corrs, v_logits = x.split(self.splits, -1)\n",
        "        mix_logp = F.log_softmax(mix_logits, -1) # [...,k]\n",
        "        scales = torch.exp(scales) # [...,k*d]\n",
        "        corrs = torch.tanh(corrs) # [...,k]\n",
        "        v_logp = F.log_softmax(v_logits, -1) # [...,3]\n",
        "\n",
        "        # reshape [...,k*d] -> [...,k,d]\n",
        "        means = means.reshape(*means.shape[:-1], -1, 2)\n",
        "        scales = scales.reshape(*scales.shape[:-1], -1, 2)\n",
        "\n",
        "        if T != 1:\n",
        "            v_logp = F.log_softmax(v_logp/T, -1)\n",
        "            mix_logp = F.log_softmax(mix_logp/T, -1)\n",
        "            scales = scales * math.sqrt(T)\n",
        "\n",
        "        return mix_logp, means, scales, corrs, v_logp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvlvIGsZTr8d"
      },
      "outputs": [],
      "source": [
        "__all__ = ['LSTMCell', 'LayerNormLSTMCell', 'HyperLSTMCell', 'LSTMLayer',\n",
        "           'BiLSTMLayer']\n",
        "\n",
        "\n",
        "\n",
        "def init_orthogonal_(weight, hsize):\n",
        "    assert weight.size(0) == 4*hsize\n",
        "    for i in range(4):\n",
        "        nn.init.orthogonal_(weight[i*hsize:(i+1)*hsize])\n",
        "\n",
        "\n",
        "# ---- LSTMCell ----\n",
        "\n",
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 forget_bias=1.,\n",
        "                 r_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.weight_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
        "        self.weight_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
        "        self.bias = nn.Parameter(torch.empty(4 * hidden_size))\n",
        "        self.r_dropout = nn.Dropout(r_dropout) if r_dropout > 0 else nn.Identity()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.forget_bias = forget_bias\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight_ih)\n",
        "        init_orthogonal_(self.weight_hh, hsize=self.hidden_size)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        return 2 * self.hidden_size\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n",
        "        h, c = state\n",
        "        Wi = torch.mm(x, self.weight_ih.t())\n",
        "        Wh = torch.mm(h, self.weight_hh.t())\n",
        "        linear = Wi + Wh + self.bias\n",
        "\n",
        "        # split and apply activations\n",
        "        i_gate, f_gate, o_gate, c_cand = linear.chunk(4, 1)\n",
        "        i_gate = torch.sigmoid(i_gate)\n",
        "        f_gate = torch.sigmoid(f_gate + self.forget_bias)\n",
        "        o_gate = torch.sigmoid(o_gate)\n",
        "        c_cand = torch.tanh(c_cand)\n",
        "\n",
        "        # update hidden and cell states\n",
        "        c = f_gate * c + i_gate * self.r_dropout(c_cand)\n",
        "        h = o_gate * torch.tanh(c)\n",
        "        state = h, c\n",
        "\n",
        "        return h, state\n",
        "\n",
        "\n",
        "\n",
        "# ---- LayerNormLSTMCell ----\n",
        "\n",
        "class ChunkLayerNorm(nn.Module):\n",
        "    def __init__(self, num_units, chunks, eps=1e-5, affine=True):\n",
        "        super().__init__()\n",
        "        if affine:\n",
        "            self.weight = nn.Parameter(torch.empty(chunks*num_units))\n",
        "            self.bias = nn.Parameter(torch.empty(chunks*num_units))\n",
        "        self.num_units = num_units\n",
        "        self.chunks = chunks\n",
        "        self.eps = eps\n",
        "        self.affine = affine\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.affine:\n",
        "            nn.init.ones_(self.weight)\n",
        "            nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # type: (Tensor) -> Tensor\n",
        "        x = x.reshape(x.size(0), self.chunks, self.num_units)\n",
        "        x = F.layer_norm(x, (self.num_units,), None, None, self.eps)\n",
        "        x = x.reshape(x.size(0), self.chunks*self.num_units)\n",
        "        if self.affine:\n",
        "            x = x * self.weight + self.bias\n",
        "        return x\n",
        "\n",
        "class LayerNormLSTMCell(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 forget_bias=1.,\n",
        "                 r_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.weight_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
        "        self.weight_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
        "        self.r_dropout = nn.Dropout(r_dropout) if r_dropout > 0 else nn.Identity()\n",
        "        self.layernorm_h = ChunkLayerNorm(hidden_size, 4)\n",
        "        self.layernorm_c = nn.LayerNorm(hidden_size)\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.forget_bias = forget_bias\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight_ih)\n",
        "        init_orthogonal_(self.weight_hh, hsize=self.hidden_size)\n",
        "        self.layernorm_h.reset_parameters()\n",
        "        self.layernorm_c.reset_parameters()\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        return 2 * self.hidden_size\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n",
        "        h, c = state\n",
        "        Wi = torch.mm(x, self.weight_ih.t())\n",
        "        Wh = torch.mm(h, self.weight_hh.t())\n",
        "        linear = self.layernorm_h(Wi + Wh)\n",
        "\n",
        "        # split and apply activations\n",
        "        i_gate, f_gate, o_gate, c_cand = linear.chunk(4, 1)\n",
        "        i_gate = torch.sigmoid(i_gate)\n",
        "        f_gate = torch.sigmoid(f_gate + self.forget_bias)\n",
        "        o_gate = torch.sigmoid(o_gate)\n",
        "        c_cand = torch.tanh(c_cand)\n",
        "\n",
        "        # update hidden and cell states\n",
        "        c = f_gate * c + i_gate * self.r_dropout(c_cand)\n",
        "        h = o_gate * torch.tanh(self.layernorm_c(c))\n",
        "        state = h, c\n",
        "\n",
        "        return h, state\n",
        "\n",
        "\n",
        "\n",
        "# ---- HyperLSTMCell ----\n",
        "\n",
        "# HyperNormalization\n",
        "class HyperNorm(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, output_size, bias=True):\n",
        "        super().__init__()\n",
        "        self.scale_net = nn.Sequential(\n",
        "            nn.Linear(input_size, embed_size, bias=True),\n",
        "            nn.Linear(embed_size, output_size, bias=False)\n",
        "        )\n",
        "        if bias:\n",
        "            self.bias_net = nn.Sequential(\n",
        "                nn.Linear(input_size, embed_size, bias=False),\n",
        "                nn.Linear(embed_size, output_size, bias=False)\n",
        "            )\n",
        "        else:\n",
        "            self.bias_net = None\n",
        "        self.embed_size = embed_size\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init_gamma = 0.1\n",
        "        nn.init.constant_(self.scale_net[0].weight, 0.)\n",
        "        nn.init.constant_(self.scale_net[0].bias, 1.)\n",
        "        nn.init.constant_(self.scale_net[1].weight, init_gamma/self.embed_size)\n",
        "        if self.bias_net is not None:\n",
        "            nn.init.normal_(self.bias_net[0].weight, 0., 0.01)\n",
        "            nn.init.constant_(self.bias_net[1].weight, 0.)\n",
        "\n",
        "    def forward(self, x, hyper_out):\n",
        "        # type: (Tensor, Tensor) -> Tensor\n",
        "        scale = self.scale_net(hyper_out)\n",
        "        out = scale * x\n",
        "        if self.bias_net is not None:\n",
        "            bias = self.bias_net(hyper_out)\n",
        "            out = out + bias\n",
        "        return out\n",
        "\n",
        "\n",
        "class HyperLSTMCell(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 forget_bias=1.,\n",
        "                 r_dropout=0.1,\n",
        "                 layer_norm=True,\n",
        "                 hyper_hidden_size=256,\n",
        "                 hyper_embed_size=32,\n",
        "                 hyper_r_dropout=0.1):\n",
        "        super().__init__()\n",
        "        # hyper LSTM cell\n",
        "        hyper_init = LayerNormLSTMCell if layer_norm else LSTMCell\n",
        "        self.hyper_cell = hyper_init(\n",
        "            input_size,\n",
        "            hyper_hidden_size,\n",
        "            forget_bias=forget_bias,\n",
        "            r_dropout=hyper_r_dropout\n",
        "        )\n",
        "        # outer LSTM params\n",
        "        self.weight_ih = nn.Parameter(torch.empty(4 * hidden_size, input_size))\n",
        "        self.weight_hh = nn.Parameter(torch.empty(4 * hidden_size, hidden_size))\n",
        "        self.r_dropout = nn.Dropout(r_dropout) if r_dropout > 0 else nn.Identity()\n",
        "        if layer_norm:\n",
        "            self.layernorm_h = ChunkLayerNorm(hidden_size, 4)\n",
        "            self.layernorm_c = nn.LayerNorm(hidden_size)\n",
        "            self.bias = None\n",
        "        else:\n",
        "            self.layernorm_h = self.layernorm_c = None\n",
        "            self.bias = nn.Parameter(torch.empty(4 * hidden_size))\n",
        "        # hypernorm layers\n",
        "        def norm_init(use_bias):\n",
        "            return HyperNorm(hyper_hidden_size, hyper_embed_size, hidden_size, use_bias)\n",
        "        self.norms_x = nn.ModuleList([\n",
        "            norm_init(use_bias=False),\n",
        "            norm_init(use_bias=False),\n",
        "            norm_init(use_bias=False),\n",
        "            norm_init(use_bias=False)\n",
        "        ])\n",
        "        self.norms_h = nn.ModuleList([\n",
        "            norm_init(use_bias=True),\n",
        "            norm_init(use_bias=True),\n",
        "            norm_init(use_bias=True),\n",
        "            norm_init(use_bias=True)\n",
        "        ])\n",
        "        # misc\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.forget_bias = forget_bias\n",
        "        self.layer_norm = layer_norm\n",
        "        self.hyper_hidden_size = hyper_hidden_size\n",
        "        self.hyper_embed_size = hyper_embed_size\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.hyper_cell.reset_parameters()\n",
        "        nn.init.xavier_uniform_(self.weight_ih)\n",
        "        init_orthogonal_(self.weight_hh, hsize=self.hidden_size)\n",
        "        if self.layer_norm:\n",
        "            self.layernorm_h.reset_parameters()\n",
        "            self.layernorm_c.reset_parameters()\n",
        "        else:\n",
        "            nn.init.zeros_(self.bias)\n",
        "        for norm in self.norms_x:\n",
        "            norm.reset_parameters()\n",
        "        for norm in self.norms_h:\n",
        "            norm.reset_parameters()\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        return 2 * (self.hidden_size + self.hyper_hidden_size)\n",
        "\n",
        "    # def _apply_hypernorm(self, h_hyper, Wx, Wh):\n",
        "    #     gates_x = [norm(gate,h_hyper) for norm,gate in zip(self.norms_x, Wx.chunk(4,1))]\n",
        "    #     gates_h = [norm(gate,h_hyper) for norm,gate in zip(self.norms_h, Wh.chunk(4,1))]\n",
        "    #     gates = [gx+gh for gx,gh in zip(gates_x, gates_h)]\n",
        "    #     gates = torch.cat(gates, 1)\n",
        "    #     return gates\n",
        "\n",
        "    def _apply_hypernorm(self, h_hyper, Wx, Wh):\n",
        "        # type: (Tensor, Tensor, Tensor) -> Tensor\n",
        "        gates_x = Wx.chunk(4,1)\n",
        "        gates_h = Wh.chunk(4,1)\n",
        "        gates = torch.jit.annotate(List[Tensor], [])\n",
        "        i = 0\n",
        "        for norm in self.norms_x:\n",
        "            g_in = gates_x[i]\n",
        "            g_out = norm(g_in, h_hyper)\n",
        "            gates += [g_out]\n",
        "            i += 1\n",
        "        i = 0\n",
        "        for norm in self.norms_h:\n",
        "            g_in = gates_h[i]\n",
        "            g_out = norm(g_in, h_hyper)\n",
        "            gates[i] += g_out\n",
        "            i += 1\n",
        "        gates = torch.cat(gates, 1)\n",
        "        return gates\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n",
        "        h_total, c_total = state\n",
        "        h, h_hyper = h_total.split((self.hidden_size, self.hyper_hidden_size), 1)\n",
        "        c, c_hyper = c_total.split((self.hidden_size, self.hyper_hidden_size), 1)\n",
        "\n",
        "        # hyper lstm cell\n",
        "        _, (h_hyper, c_hyper) = self.hyper_cell(x, (h_hyper, c_hyper))\n",
        "\n",
        "        # compute linear gate activations\n",
        "        Wx = torch.mm(x, self.weight_ih.t())\n",
        "        Wh = torch.mm(h, self.weight_hh.t())\n",
        "        gates = self._apply_hypernorm(h_hyper, Wx, Wh)\n",
        "        if self.layernorm_h is not None:\n",
        "            gates = self.layernorm_h(gates)\n",
        "        else:\n",
        "            gates = gates + self.bias\n",
        "\n",
        "        # split and apply activations\n",
        "        i_gate, f_gate, o_gate, c_cand = gates.chunk(4, 1)\n",
        "        i_gate = torch.sigmoid(i_gate)\n",
        "        f_gate = torch.sigmoid(f_gate + self.forget_bias)\n",
        "        o_gate = torch.sigmoid(o_gate)\n",
        "        c_cand = torch.tanh(c_cand)\n",
        "\n",
        "        # update hidden and cell states\n",
        "        c = f_gate * c + i_gate * self.r_dropout(c_cand)\n",
        "        c_input = self.layernorm_c(c) if (self.layernorm_c is not None) else c\n",
        "        h = o_gate * torch.tanh(c_input)\n",
        "\n",
        "        # collect total state\n",
        "        h_total = torch.cat((h, h_hyper), 1)\n",
        "        c_total = torch.cat((c, c_hyper), 1)\n",
        "        state = h_total, c_total\n",
        "\n",
        "        return h, state\n",
        "\n",
        "\n",
        "\n",
        "_cell_types = {\n",
        "    'lstm' : LSTMCell,\n",
        "    'layer_norm' : LayerNormLSTMCell,\n",
        "    'hyper' : HyperLSTMCell\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---- LSTM Layer ----\n",
        "\n",
        "class LSTMLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 cell,\n",
        "                 batch_first=False,\n",
        "                 reverse=False):\n",
        "        super().__init__()\n",
        "        self.cell = cell\n",
        "        self.dim = 1 if batch_first else 0\n",
        "        self.reverse = reverse\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.cell.reset_parameters()\n",
        "\n",
        "    def forward(self, inputs, state):\n",
        "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n",
        "        if self.reverse:\n",
        "            inputs = torch.flip(inputs, dims=[self.dim])\n",
        "        inputs = inputs.unbind(dim=self.dim)\n",
        "        outputs = []\n",
        "        for t in range(len(inputs)):\n",
        "            out, state = self.cell(inputs[t], state)\n",
        "            outputs += [out]\n",
        "        outputs = torch.stack(outputs, dim=self.dim)\n",
        "        if self.reverse:\n",
        "            outputs = torch.flip(outputs, dims=[self.dim])\n",
        "\n",
        "        return outputs, state\n",
        "\n",
        "\n",
        "class BiLSTMLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 cell_f,\n",
        "                 cell_r,\n",
        "                 batch_first=False):\n",
        "        super().__init__()\n",
        "        self.layer_f = LSTMLayer(cell_f, batch_first)\n",
        "        self.layer_r = LSTMLayer(cell_r, batch_first, reverse=True)\n",
        "        self.dim = 1 if batch_first else 0\n",
        "\n",
        "    def forward(self, inputs, states):\n",
        "        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n",
        "        hx, cx = states\n",
        "        state_f = torch.jit.annotate(Tuple[Tensor,Tensor], (hx[0], cx[0]))\n",
        "        state_r = torch.jit.annotate(Tuple[Tensor,Tensor], (hx[1], cx[1]))\n",
        "        out_f, out_state_f = self.layer_f(inputs, state_f)\n",
        "        out_r, out_state_r = self.layer_r(inputs, state_r)\n",
        "        hy = torch.stack((out_state_f[0], out_state_r[0]), 0)\n",
        "        cy = torch.stack((out_state_f[1], out_state_r[1]), 0)\n",
        "\n",
        "        out = torch.cat((out_f, out_r), -1)\n",
        "        out_states = torch.jit.annotate(Tuple[Tensor,Tensor], (hy, cy))\n",
        "\n",
        "        return out, out_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJAaZYteTr8e"
      },
      "outputs": [],
      "source": [
        "__all__ = ['SketchRNN', 'model_step', 'sample_conditional',\n",
        "           'sample_unconditional']\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_size, z_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.LSTM(5, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.output = nn.Linear(2*hidden_size, 2*z_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for i in range(2):\n",
        "            weight_ih, weight_hh, bias_ih, bias_hh = self.rnn.all_weights[i]\n",
        "            nn.init.xavier_uniform_(weight_ih)\n",
        "            init_orthogonal_(weight_hh, hsize=self.hidden_size)\n",
        "            nn.init.zeros_(bias_ih)\n",
        "            nn.init.zeros_(bias_hh)\n",
        "        nn.init.normal_(self.output.weight, 0., 0.001)\n",
        "        nn.init.zeros_(self.output.bias)\n",
        "\n",
        "    def forward(self, x, lengths=None):\n",
        "        if lengths is not None:\n",
        "            x = rnn_utils.pack_padded_sequence(\n",
        "                x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        _, (x, _) = self.rnn(x) # [2,batch,hid]\n",
        "        x = x.permute(1,0,2).flatten(1).contiguous() # [batch,2*hid]\n",
        "        z_mean, z_logvar = self.output(x).chunk(2, 1)\n",
        "        z = z_mean + torch.exp(0.5*z_logvar) * torch.randn_like(z_logvar)\n",
        "        return z, z_mean, z_logvar\n",
        "\n",
        "\n",
        "class SketchRNN(nn.Module):\n",
        "    def __init__(self, hps):\n",
        "        super().__init__()\n",
        "        # check inputs\n",
        "        assert hps.enc_model in ['lstm', 'layer_norm', 'hyper']\n",
        "        assert hps.dec_model in ['lstm', 'layer_norm', 'hyper']\n",
        "        if hps.enc_model in ['layer_norm', 'hyper']:\n",
        "            raise NotImplementedError('LayerNormLSTM and HyperLSTM not yet '\n",
        "                                      'implemented for bi-directional encoder.')\n",
        "        # encoder modules\n",
        "        self.encoder = Encoder(hps.enc_rnn_size, hps.z_size) # enc_rnn_size --> RNN_hidden_size\n",
        "        # decoder modules\n",
        "        cell_fn = _cell_types[hps.dec_model]\n",
        "        self.cell = cell_fn(5+hps.z_size, hps.dec_rnn_size, r_dropout=hps.r_dropout)\n",
        "        self.decoder = torch.jit.script(LSTMLayer(self.cell, batch_first=True))\n",
        "        self.init = nn.Linear(hps.z_size, self.cell.state_size)\n",
        "        self.param_layer = ParameterLayer(hps.dec_rnn_size, k=hps.num_mixture)\n",
        "        # loss modules\n",
        "        self.loss_kl = KLLoss(\n",
        "            hps.kl_weight,\n",
        "            eta_min=hps.kl_weight_start,\n",
        "            R=hps.kl_decay_rate,\n",
        "            kl_min=hps.kl_tolerance)\n",
        "        self.loss_draw = DrawingLoss(reg_covar=hps.reg_covar)\n",
        "        self.max_len = hps.max_seq_len\n",
        "        self.z_size = hps.z_size\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        reset = lambda m: (hasattr(m, 'reset_parameters') and\n",
        "                           not isinstance(m, torch.jit.ScriptModule))\n",
        "        for m in filter(reset, self.children()):\n",
        "            m.reset_parameters()\n",
        "        nn.init.normal_(self.init.weight, 0., 0.001)\n",
        "        nn.init.zeros_(self.init.bias)\n",
        "\n",
        "    def _forward(self, enc_inputs, dec_inputs, enc_lengths=None):\n",
        "        # encoder forward\n",
        "        z, z_mean, z_logvar = self.encoder(enc_inputs, enc_lengths)\n",
        "\n",
        "        # initialize decoder state\n",
        "        state = torch.tanh(self.init(z)).chunk(2, dim=-1)\n",
        "\n",
        "        # append z to decoder inputs\n",
        "        z_rep = z[:,None].expand(-1,self.max_len,-1)\n",
        "        dec_inputs = torch.cat((dec_inputs, z_rep), dim=-1)\n",
        "\n",
        "        # decoder forward\n",
        "        output, _ = self.decoder(dec_inputs, state)\n",
        "\n",
        "        # mixlayer outputs\n",
        "        params = self.param_layer(output)\n",
        "\n",
        "        return params, z_mean, z_logvar\n",
        "\n",
        "    def forward(self, data, lengths=None):\n",
        "        enc_inputs = data[:,1:self.max_len+1,:] # remove sos\n",
        "        dec_inputs = data[:,:self.max_len,:] # keep sos\n",
        "        return self._forward(enc_inputs, dec_inputs, lengths)\n",
        "\n",
        "\n",
        "# ---- model step code (for train/eval) ----\n",
        "\n",
        "def model_step(model, data, lengths=None):\n",
        "    # model forward\n",
        "    params, z_mean, z_logvar = model(data, lengths)\n",
        "\n",
        "    # prepare targets\n",
        "    targets = data[:,1:model.max_len+1,:]\n",
        "    x, v_onehot = targets.split([2,3], -1)\n",
        "    assert torch.all(v_onehot.sum(-1) == 1)\n",
        "    v = v_onehot.argmax(-1)\n",
        "\n",
        "    # compute losses\n",
        "    loss_kl = model.loss_kl(z_mean, z_logvar)\n",
        "    loss_draw = model.loss_draw(x, v, params)\n",
        "    loss = loss_kl + loss_draw\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "# ---- Sampling code -----\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_from_z(model, z, T=1):\n",
        "    # initialize decoder state\n",
        "    state = torch.tanh(model.init(z)).chunk(2, dim=-1)\n",
        "\n",
        "    # decode target sequences w/ attention\n",
        "    x = torch.zeros(1, 2, dtype=torch.float32, device=z.device)\n",
        "    v = torch.zeros(1, dtype=torch.long, device=z.device)\n",
        "    x_samp, v_samp = [x], [v]\n",
        "    for t in range(model.max_len):\n",
        "        # compute parameters for next step\n",
        "        v = F.one_hot(v,3).float()\n",
        "        dec_inputs = torch.cat((x,v,z), -1)\n",
        "        output, state = model.decoder.cell(dec_inputs, state)\n",
        "        mix_logp, means, scales, corrs, v_logp = model.param_layer(output, T=T)\n",
        "        # sample next step\n",
        "        v = D.Categorical(v_logp.exp()).sample() # [1]\n",
        "        if v.item() == 2:\n",
        "            break\n",
        "        x = sample_gmm(mix_logp, means, scales, corrs) # [1,2]\n",
        "        # append sample and continue\n",
        "        x_samp.append(x)\n",
        "        v_samp.append(v)\n",
        "    return torch.cat(x_samp), torch.cat(v_samp)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unconditional(model, T=1, z_scale=1, device=torch.device('cpu')):\n",
        "    model.eval().to(device)\n",
        "    z = z_scale * torch.randn(1, model.z_size, dtype=torch.float, device=device)\n",
        "    return sample_from_z(model, z, T=T)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_conditional(model, data, lengths, T=1, device=torch.device('cpu')):\n",
        "    model.eval().to(device)\n",
        "    data, lengths = check_sample_inputs(data, lengths, device)\n",
        "    enc_inputs = data[:,1:,:]\n",
        "    z, _, _ = model.encoder(enc_inputs, lengths)\n",
        "    return sample_from_z(model, z, T=T)\n",
        "\n",
        "def check_sample_inputs(data, lengths, device):\n",
        "    assert isinstance(data, torch.Tensor)\n",
        "    assert data.dim() == 2\n",
        "    assert isinstance(lengths, torch.Tensor) or isinstance(lengths, numbers.Integral)\n",
        "    data = data.unsqueeze(0)\n",
        "    if torch.is_tensor(lengths):\n",
        "        assert lengths.dim() == 0\n",
        "        lengths = lengths.unsqueeze(0)\n",
        "    else:\n",
        "        lengths = torch.tensor([lengths])\n",
        "    return data.to(device), lengths.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzqh3zocTr8f"
      },
      "outputs": [],
      "source": [
        "__all__ = ['AverageMeter', 'ModelCheckpoint']\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0.\n",
        "        self.avg = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0.\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0.\n",
        "        self.avg = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0.\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "class ModelCheckpoint:\n",
        "    def __init__(self,\n",
        "                 save_dir,\n",
        "                 save_freq=5,\n",
        "                 losses_only=False,\n",
        "                 best_only=True,\n",
        "                 tensorboard=False):\n",
        "        if os.path.exists(save_dir):\n",
        "            warnings.warn('Save directory already exists! Removing old '\n",
        "                          'directory contents.')\n",
        "            shutil.rmtree(save_dir)\n",
        "        os.mkdir(save_dir)\n",
        "        self.model_file = os.path.join(save_dir, 'model.pt')\n",
        "        self.optimizer_file = os.path.join(save_dir, 'optimizer.pt')\n",
        "        self.losses_file = os.path.join(save_dir, 'losses.pt')\n",
        "        self.save_freq = save_freq\n",
        "        self.losses_only = losses_only\n",
        "        self.best_only = best_only\n",
        "        self.losses = np.array([], dtype=np.float32)\n",
        "        self.val_losses = np.array([], dtype=np.float32)\n",
        "        self.best = float('inf')\n",
        "        if tensorboard:\n",
        "            from torch.utils.tensorboard import SummaryWriter\n",
        "            log_dir = os.path.join(save_dir, 'logs')\n",
        "            self.writer = SummaryWriter(log_dir)\n",
        "        else:\n",
        "            self.writer = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _module(model):\n",
        "        is_dp = isinstance(model, nn.DataParallel)\n",
        "        is_ddp = isinstance(model, nn.parallel.DistributedDataParallel)\n",
        "        if is_dp or is_ddp:\n",
        "            return model.module\n",
        "        return model\n",
        "\n",
        "    def __call__(self, epoch, model, optimizer, loss, val_loss):\n",
        "        # update loss trackers\n",
        "        self.losses = np.append(self.losses, loss)\n",
        "        self.val_losses = np.append(self.val_losses, val_loss)\n",
        "        if self.writer is not None:\n",
        "            self.writer.add_scalar('loss', loss, epoch)\n",
        "            self.writer.add_scalar('loss', val_loss, epoch)\n",
        "            self.writer.flush()\n",
        "\n",
        "        # save losses\n",
        "        torch.save({\n",
        "            'train': torch.from_numpy(self.losses).float(),\n",
        "            'valid': torch.from_numpy(self.val_losses).float()\n",
        "            }, self.losses_file)\n",
        "\n",
        "        if self.losses_only:\n",
        "            return\n",
        "\n",
        "        if epoch % self.save_freq == 0:\n",
        "            model = self._module(model)\n",
        "            current_loss = self.val_losses[-5:].mean()\n",
        "            if (not self.best_only) or (current_loss < self.best):\n",
        "                torch.save(model.state_dict(), self.model_file)\n",
        "                torch.save(optimizer.state_dict(), self.optimizer_file)\n",
        "            if current_loss < self.best:\n",
        "                self.best = current_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoS5gPJ5Tr8f"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, optimizer, scheduler, device,\n",
        "                grad_clip=None):\n",
        "    model.train()\n",
        "    loss_meter = AverageMeter()\n",
        "    with tqdm(total=len(data_loader.dataset)) as progress_bar:\n",
        "        for data, lengths in data_loader:\n",
        "            data = data.to(device, non_blocking=True)\n",
        "            lengths = lengths.to(device, non_blocking=True)\n",
        "            # training step\n",
        "            optimizer.zero_grad()\n",
        "            loss = model_step(model, data, lengths)\n",
        "            loss.backward()\n",
        "            if grad_clip is not None:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            # update loss meter and progbar\n",
        "            loss_meter.update(loss.item(), data.size(0))\n",
        "            progress_bar.set_postfix(loss=loss_meter.avg)\n",
        "            progress_bar.update(data.size(0))\n",
        "\n",
        "    return loss_meter.avg\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, data_loader, device):\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter()\n",
        "    for data, lengths in data_loader:\n",
        "        data = data.to(device, non_blocking=True)\n",
        "        lengths = lengths.to(device, non_blocking=True)\n",
        "        loss = model_step(model, data, lengths)\n",
        "        loss_meter.update(loss.item(), data.size(0))\n",
        "    return loss_meter.avg\n",
        "\n",
        "\n",
        "def train_sketch_rnn(args):\n",
        "    torch.manual_seed(884)\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    device = torch.device('cuda') if use_gpu else torch.device('cpu')\n",
        "    print('Using device:', device)\n",
        "    saver = ModelCheckpoint(args.save_dir) if (args.save_dir is not None) else None\n",
        "\n",
        "    # initialize train and val datasets\n",
        "    train_strokes, valid_strokes, test_strokes = load_strokes(args.data_dir, args)\n",
        "    train_data = SketchRNNDataset(\n",
        "        train_strokes,\n",
        "        max_len=args.max_seq_len,\n",
        "        random_scale_factor=args.random_scale_factor,\n",
        "        augment_stroke_prob=args.augment_stroke_prob\n",
        "    )\n",
        "    val_data = SketchRNNDataset(\n",
        "        valid_strokes,\n",
        "        max_len=args.max_seq_len,\n",
        "        scale_factor=train_data.scale_factor,\n",
        "        random_scale_factor=0.0,\n",
        "        augment_stroke_prob=0.0\n",
        "    )\n",
        "\n",
        "    # initialize data loaders\n",
        "    collate_fn = lambda x : collate_drawings(x, args.max_seq_len)\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=args.batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=True,\n",
        "        pin_memory=use_gpu,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=args.batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=False,\n",
        "        pin_memory=use_gpu,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "\n",
        "    # model & optimizer\n",
        "    model = SketchRNN(args).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, args.lr_decay)\n",
        "\n",
        "    for epoch in range(args.num_epochs):\n",
        "        print('training epoch %i' % (epoch+1))\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, optimizer, scheduler, device, args.grad_clip)\n",
        "        val_loss = eval_epoch(model, val_loader, device)\n",
        "        print('Epoch %0.3i, Train Loss: %0.4f, Valid Loss: %0.4f' %\n",
        "              (epoch+1, train_loss, val_loss))\n",
        "        if saver is not None:\n",
        "            saver(epoch, model, optimizer, train_loss, val_loss)\n",
        "        time.sleep(0.5) # avoids progress bar issue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbQvN7oOTr8f",
        "outputId": "8c494bdb-1073-4e19-f7a2-24b3b64386f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Downloading https://storage.googleapis.com/quickdraw_dataset/sketchrnn/banana.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15648\\2026264584.py:33: UserWarning: Save directory already exists! Removing old directory contents.\n",
            "  warnings.warn('Save directory already exists! Removing old '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded and saved banana.npz to data\\banana.npz\n",
            "Loaded 70000/2500/2500 from banana.npz\n",
            "Dataset combined: 75000 (70000/2500/2500), avg len 32\n",
            "hps.max_seq_len 73.\n",
            "total drawings <= max_seq_len is 70000\n",
            "total drawings <= max_seq_len is 2500\n",
            "training epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:35<00:00, 449.99it/s, loss=0.873]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001, Train Loss: 0.8732, Valid Loss: 0.2160\n",
            "training epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:17<00:00, 508.56it/s, loss=0.277]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002, Train Loss: 0.2768, Valid Loss: -0.0857\n",
            "training epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:17<00:00, 507.51it/s, loss=0.053] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003, Train Loss: 0.0530, Valid Loss: -0.2797\n",
            "training epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:18<00:00, 506.55it/s, loss=-0.099]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004, Train Loss: -0.0990, Valid Loss: -0.4426\n",
            "training epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:28<00:00, 471.40it/s, loss=-0.212]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005, Train Loss: -0.2116, Valid Loss: -0.5399\n",
            "training epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [03:26<00:00, 339.44it/s, loss=-0.299]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006, Train Loss: -0.2986, Valid Loss: -0.6583\n",
            "training epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:18<00:00, 506.52it/s, loss=-0.373]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007, Train Loss: -0.3728, Valid Loss: -0.7330\n",
            "training epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:19<00:00, 502.62it/s, loss=-0.43] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008, Train Loss: -0.4301, Valid Loss: -0.7838\n",
            "training epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [03:53<00:00, 299.48it/s, loss=-0.474]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009, Train Loss: -0.4736, Valid Loss: -0.8361\n",
            "training epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:28<00:00, 471.63it/s, loss=-0.508]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010, Train Loss: -0.5081, Valid Loss: -0.8956\n",
            "training epoch 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:10<00:00, 538.04it/s, loss=-0.534]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011, Train Loss: -0.5343, Valid Loss: -0.9001\n",
            "training epoch 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:15<00:00, 517.95it/s, loss=-0.556]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012, Train Loss: -0.5557, Valid Loss: -0.9283\n",
            "training epoch 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:14<00:00, 519.79it/s, loss=-0.571]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013, Train Loss: -0.5714, Valid Loss: -0.9634\n",
            "training epoch 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:17<00:00, 507.60it/s, loss=-0.581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014, Train Loss: -0.5808, Valid Loss: -0.9677\n",
            "training epoch 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:16<00:00, 513.41it/s, loss=-0.591]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015, Train Loss: -0.5908, Valid Loss: -0.9839\n",
            "training epoch 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:14<00:00, 519.26it/s, loss=-0.595]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016, Train Loss: -0.5955, Valid Loss: -0.9951\n",
            "training epoch 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:17<00:00, 507.48it/s, loss=-0.598]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017, Train Loss: -0.5977, Valid Loss: -0.9976\n",
            "training epoch 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:17<00:00, 509.29it/s, loss=-0.601]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018, Train Loss: -0.6005, Valid Loss: -0.9966\n",
            "training epoch 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:16<00:00, 513.57it/s, loss=-0.599]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019, Train Loss: -0.5993, Valid Loss: -1.0046\n",
            "training epoch 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:15<00:00, 515.76it/s, loss=-0.597]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020, Train Loss: -0.5972, Valid Loss: -1.0039\n",
            "training epoch 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:14<00:00, 521.37it/s, loss=-0.597]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021, Train Loss: -0.5971, Valid Loss: -0.9924\n",
            "training epoch 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:12<00:00, 526.98it/s, loss=-0.594]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022, Train Loss: -0.5939, Valid Loss: -0.9963\n",
            "training epoch 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:14<00:00, 519.53it/s, loss=-0.591]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023, Train Loss: -0.5911, Valid Loss: -0.9962\n",
            "training epoch 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 70000/70000 [02:15<00:00, 516.36it/s, loss=-0.591]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024, Train Loss: -0.5906, Valid Loss: -0.9942\n",
            "training epoch 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 29280/70000 [00:57<01:19, 512.99it/s, loss=-0.589]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[110], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m hparams()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_sketch_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[107], line 86\u001b[0m, in \u001b[0;36mtrain_sketch_rnn\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining epoch \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 86\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m eval_epoch(model, val_loader, device)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m%0.3i\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m, Valid Loss: \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     90\u001b[0m           (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, train_loss, val_loss))\n",
            "Cell \u001b[1;32mIn[107], line 6\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, scheduler, device, grad_clip)\u001b[0m\n\u001b[0;32m      4\u001b[0m loss_meter \u001b[38;5;241m=\u001b[39m AverageMeter()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader\u001b[38;5;241m.\u001b[39mdataset)) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m----> 6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\anaconda3\\envs\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
            "File \u001b[1;32md:\\anaconda3\\envs\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32md:\\anaconda3\\envs\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[100], line 155\u001b[0m, in \u001b[0;36mSketchRNNDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    153\u001b[0m     data \u001b[38;5;241m=\u001b[39m random_scale(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_scale_factor)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment_stroke_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 155\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_stroke_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "Cell \u001b[1;32mIn[100], line 184\u001b[0m, in \u001b[0;36mrandom_augment\u001b[1;34m(data, prob)\u001b[0m\n\u001b[0;32m    182\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    183\u001b[0m check \u001b[38;5;241m=\u001b[39m candidate[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m prev_stroke[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m prob):\n\u001b[0;32m    185\u001b[0m     stroke[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m candidate[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    186\u001b[0m     stroke[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m candidate[\u001b[38;5;241m1\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# args = hparams()\n",
        "# train_sketch_rnn(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz3EimbOTr8f",
        "outputId": "82580ec3-7615-44ea-e29d-90a1b57e9bc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15648\\947721698.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('results/model.pt'))  # Path to trained model\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading local file: data\\cat.npz\n",
            "Loaded 70000/2500/2500 from cat.npz\n",
            "Loading local file: data\\car.npz\n",
            "Loaded 70000/2500/2500 from car.npz\n",
            "Dataset combined: 150000 (140000/5000/5000), avg len 69\n",
            "hps.max_seq_len 129.\n",
            "total drawings <= max_seq_len is 5000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def convert_to_5d(sample):\n",
        "    \"\"\"Converts a 3D sketch sample (Δx, Δy, pen_state) to 5D format.\"\"\"\n",
        "    sample = sample.squeeze(0)  # Remove batch dimension if present\n",
        "    out = torch.zeros(sample.size(0), 5)\n",
        "    out[:, :2] = sample[:, :2]  # Copy Δx and Δy\n",
        "    out[:, 2] = 1 - sample[:, 2]  # p1 = 1 - pen_up\n",
        "    out[:, 3] = sample[:, 2]      # p2 = pen_up\n",
        "    out[:, 4] = 0                 # p3 = 0 (no end-of-sequence here)\n",
        "    out[-1,4] = 1             # Set p3 to 1 for the last point (end of sequence)\n",
        "    return out.unsqueeze(0)  # Restore batch dimension after conversion\n",
        "\n",
        "# Load model\n",
        "hps = hparams()\n",
        "model = SketchRNN(hps)\n",
        "model.load_state_dict(torch.load('results/model.pt'))  # Path to trained model\n",
        "model.eval()\n",
        "\n",
        "# Load test dataset\n",
        "data_dir = 'data'  # Update with correct path if needed\n",
        "_, _, test_strokes = load_strokes(data_dir, hps)\n",
        "test_data = SketchRNNDataset(test_strokes, max_len=hps.max_seq_len)\n",
        "\n",
        "\n",
        "\n",
        "# # Sample one sketch from test data\n",
        "# sample_idx = torch.randint(0, len(test_data), (1,)).item()\n",
        "# sample_sketch = test_data[sample_idx]  # Add batch dimension\n",
        "\n",
        "# sample_sketch, lengths = collate_drawings([sample_sketch], hps.max_seq_len)  # Collate to max length\n",
        "# sample_sketch = sample_sketch.squeeze(0)  # Remove batch dimension\n",
        "# lengths = lengths.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "# sequence, penstate = sample_conditional(model, sample_sketch, lengths, device=torch.device('cpu'))  # Sample from model\n",
        "\n",
        "# penstate = penstate.unsqueeze(-1)  # Expand the dimension of penstate\n",
        "# sample_sketch = torch.cat((sequence, penstate), dim=-1)  # Concatenate sequence and penstate\n",
        "# sample_sketch = convert_to_5d(sample_sketch)\n",
        "# sample_sketch = sample_sketch.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "sample_sketch, penstate = sample_unconditional(model, z_scale=1, device=torch.device('cpu'))\n",
        "penstate = penstate.unsqueeze(-1)  # Expand the dimension of penstate  # Sample from model\n",
        "# # concatenate penstate to sample_sketch\n",
        "sample_sketch = torch.cat((sample_sketch, penstate), dim=-1)  # [1, max_len, 5]\n",
        "sample_sketch = convert_to_5d(sample_sketch)  # Convert to 5D format\n",
        "sample_sketch = sample_sketch.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "\n",
        "def visualize_delta_drawing(delta_sequence):\n",
        "    \"\"\"Visualizes a drawing from delta format back to absolute coordinates.\"\"\"\n",
        "    x, y = 0, 0\n",
        "    strokes = []\n",
        "    current_stroke = [[],[]]\n",
        "\n",
        "    for dx, dy, p1, p2, p3 in delta_sequence:\n",
        "        x += dx\n",
        "        y += dy\n",
        "\n",
        "        if p1 > 0.5:  # Pen is down\n",
        "            current_stroke[0].append(x)\n",
        "            current_stroke[1].append(y)\n",
        "\n",
        "        if p2 > 0.5:  # Pen is up - end of stroke\n",
        "            if current_stroke[0]:  # If stroke has points\n",
        "                strokes.append(current_stroke)\n",
        "                current_stroke = [[],[]]\n",
        "        if p3 > 0.5:\n",
        "            break\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    for stroke in strokes:\n",
        "        ax.plot(stroke[0], [-y for y in stroke[1]], 'k-')\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return strokes\n",
        "\n",
        "strokes = visualize_delta_drawing(sample_sketch.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPY2_wQLTr8g",
        "outputId": "94ba03ac-0637-43e2-8c2b-3eccfb6edea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 2 specified classes\n",
            "Processing class: cat\n",
            "Loading local file: data\\cat.npz\n",
            "Loaded 70000/2500/2500 from cat.npz\n",
            "Dataset combined: 75000 (70000/2500/2500), avg len 69\n",
            "hps.max_seq_len 129.\n",
            "total drawings <= max_seq_len is 50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting latents for cat: 100%|██████████| 782/782 [00:35<00:00, 22.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 50000 latent vectors for cat to latent_vectors\\cat_latent_vectors.json\n",
            "Processing class: car\n",
            "Loading local file: data\\car.npz\n",
            "Loaded 70000/2500/2500 from car.npz\n",
            "Dataset combined: 75000 (70000/2500/2500), avg len 69\n",
            "hps.max_seq_len 123.\n",
            "total drawings <= max_seq_len is 50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting latents for car: 100%|██████████| 782/782 [00:36<00:00, 21.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 50000 latent vectors for car to latent_vectors\\car_latent_vectors.json\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def class_to_latent_mapping(model, data_dir, output_dir, classes_to_process=None, batch_size=64,\n",
        "                           max_samples_per_class=None, separate_files=True):\n",
        "    \"\"\"\n",
        "    Extract latent vectors for specified classes from QuickDraw dataset and save them to JSON.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model containing the encoder (accessible via model.encoder)\n",
        "        data_dir: Directory containing QuickDraw .npz files\n",
        "        output_dir: Directory to save the output JSON files\n",
        "        classes_to_process: List of class names to process (e.g., ['apple', 'cat', ...])\n",
        "        batch_size: Batch size for processing\n",
        "        max_samples_per_class: Maximum number of samples to process per class\n",
        "        separate_files: Whether to save each class to a separate JSON file\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Set up dummy hyperparameters for data loading\n",
        "    class HParams:\n",
        "        def __init__(self):\n",
        "            self.max_seq_len = 250\n",
        "            self.data_set = None\n",
        "\n",
        "    hps = HParams()\n",
        "\n",
        "    # Dictionary to store all class latent vectors\n",
        "    all_class_vectors = {}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # If no specific classes provided, search for all .npz files\n",
        "    if not classes_to_process:\n",
        "        npz_files = list(Path(data_dir).glob(\"*.npz\"))\n",
        "        if not npz_files:\n",
        "            print(f\"No .npz files found in {data_dir}\")\n",
        "            return\n",
        "        print(f\"Found {len(npz_files)} .npz files to process\")\n",
        "    else:\n",
        "        # Process only the specified classes\n",
        "        print(f\"Processing {len(classes_to_process)} specified classes\")\n",
        "        npz_files = []\n",
        "        for class_name in classes_to_process:\n",
        "            # Look for different possible filename patterns\n",
        "            patterns = [\n",
        "                f\"{class_name}.npz\",\n",
        "                f\"full_numpy_bitmap_{class_name}.npz\"\n",
        "            ]\n",
        "\n",
        "            found = False\n",
        "            for pattern in patterns:\n",
        "                file_path = Path(data_dir) / pattern\n",
        "                if file_path.exists():\n",
        "                    npz_files.append(file_path)\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if not found:\n",
        "                print(f\"Warning: Could not find .npz file for class '{class_name}'\")\n",
        "\n",
        "    # Process each class (npz file)\n",
        "    for npz_file in npz_files:\n",
        "        # Extract class name from filename\n",
        "        class_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        if class_name.startswith(\"full_numpy_bitmap_\"):\n",
        "            class_name = class_name.replace(\"full_numpy_bitmap_\", \"\")\n",
        "\n",
        "        # Skip if not in the specified list (extra check in case npz_files contains more than requested)\n",
        "        if classes_to_process and class_name not in classes_to_process:\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing class: {class_name}\")\n",
        "\n",
        "        # Set up data loading for this class\n",
        "        hps.data_set = str(npz_file.name)\n",
        "\n",
        "        # Load strokes\n",
        "        train_strokes, valid_strokes, _ = load_strokes(data_dir, hps)\n",
        "\n",
        "        # Use training strokes for extracting latent vectors\n",
        "        strokes_to_use = train_strokes\n",
        "        if max_samples_per_class and len(strokes_to_use) > max_samples_per_class:\n",
        "            # Randomly sample if we have a limit\n",
        "            indices = np.random.choice(len(strokes_to_use), max_samples_per_class, replace=False)\n",
        "            strokes_to_use = strokes_to_use[indices]\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = SketchRNNDataset(strokes_to_use, max_len=hps.max_seq_len)\n",
        "\n",
        "        # Process in batches\n",
        "        latent_vectors = []\n",
        "\n",
        "        # Use torch DataLoader for batching\n",
        "        loader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=lambda x: collate_drawings(x, hps.max_seq_len),\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch, lengths in tqdm(loader, desc=f\"Extracting latents for {class_name}\"):\n",
        "                batch = batch.to(device)\n",
        "                lengths = lengths.to(device)\n",
        "\n",
        "                # Get latent vectors from encoder\n",
        "                z, z_mean, z_logvar = model.encoder(batch, lengths)\n",
        "\n",
        "                # We'll use the mean vector (z_mean) as our latent representation\n",
        "                latent_vectors.append(z_mean.cpu().numpy())\n",
        "\n",
        "        # Concatenate all batch results\n",
        "        if latent_vectors:\n",
        "            latent_vectors = np.concatenate(latent_vectors, axis=0)\n",
        "\n",
        "            # Convert to list for JSON serialization\n",
        "            latent_vectors_list = latent_vectors.tolist()\n",
        "\n",
        "            if separate_files:\n",
        "                # Save to a separate JSON file for this class\n",
        "                output_file = os.path.join(output_dir, f\"{class_name}_latent_vectors.json\")\n",
        "                with open(output_file, 'w') as f:\n",
        "                    json.dump({class_name: latent_vectors_list}, f)\n",
        "                print(f\"Saved {len(latent_vectors_list)} latent vectors for {class_name} to {output_file}\")\n",
        "            else:\n",
        "                # Add to combined dictionary\n",
        "                all_class_vectors[class_name] = latent_vectors_list\n",
        "                print(f\"Processed {len(latent_vectors_list)} latent vectors for {class_name}\")\n",
        "\n",
        "    if not separate_files and all_class_vectors:\n",
        "        # Save all classes to a single JSON file\n",
        "        output_file = os.path.join(output_dir, \"all_classes_latent_vectors.json\")\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(all_class_vectors, f)\n",
        "        print(f\"Saved latent vectors for all classes to {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "# Define parameters\n",
        "data_dir = 'data'\n",
        "output_dir = \"latent_vectors\"\n",
        "classes_to_process = ['cat','car']  # List your desired classes here\n",
        "\n",
        "# Call the function\n",
        "class_to_latent_mapping(\n",
        "    model=model,\n",
        "    data_dir=data_dir,\n",
        "    output_dir=output_dir,\n",
        "    classes_to_process=classes_to_process,\n",
        "    batch_size=64,\n",
        "    max_samples_per_class=50000,  # Limit to 50000 samples per class, for example\n",
        "    separate_files=True  # Save each class to its own file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgc90_Z7Tr8g",
        "outputId": "8504a364-a76a-4a0a-f84c-47bbcd9c82f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 JSON files to process\n",
            "Processing file: latent_vectors\\car_latent_vectors.json\n",
            "Calculated mean vector for car from 50000 samples\n",
            "Processing file: latent_vectors\\cat_latent_vectors.json\n",
            "Calculated mean vector for cat from 50000 samples\n",
            "Calculated mean latent vectors for 2 classes\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAGVCAYAAAAyrrwGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT7VJREFUeJzt3Xd0VNXexvHvpJJAIBDAEAKhSaSFKkWKAkq5gAIi0okiF+mhI0UFpb/0jlFCFREREZAiCgYQpIXQe0sooSaB9Mx5/8idkUiRMpl9Zub3WYulKwxznlDyZJezj0HTNA0hhBDCgpxUBxBCCGF/pFyEEEJYnJSLEEIIi5NyEUIIYXFSLkIIISxOykUIIYTFSbkIIYSwOCkXIYQQFiflIoQQwuKkXIQQQliclIsQQgiLk3IRQghhcVIuQgghLE7KRQghhMVJuQghhLA4KRchhBAWJ+UihBDC4qRchBBCWJyUixBCCIuTchFCCGFxUi5CCCEsTspFCCGExUm5CCGEsDgpFyGEEBYn5SKEEMLiXFQHEEIIe3b//n2OHj1KZGQkMTEx9OzZk1y5cqmOleWkXIQQwgKMRiMXLlwgMjIy048zZ86gaZr5dadOnSIsLExdUCsxaA9+1kIIIf5VbGwshw8fzlQihw8f5t69e498va+vL6VLl+a3334DYO/evVSpUsWaka1OykUIIR4jPT2d06dPPzQauXjx4iNf7+bmRpkyZQgKCiIoKIjy5ctTrlw58ufPD0CnTp1YsmQJNWvWJDw8HIPBYM1Px6qkXIQQ4h9WrVrFhAkTOHLkCElJSY98TaFChcwlYvpRsmRJXFwev9oQFRVFYGAgCQkJfPfdd7Ru3TqrPgXlpFyEEOIBJ06cICgoiNTUVAA8PT0pV65cphIpV64cuXPnfq73Hz16NJ999hkBAQEcP34cDw8PS8bXDSkXIYT4H03TqFu3Ltu3b6dhw4bMnDmTYsWK4ezsbLFrJCQkEBgYSFRUFGPGjGHYsGEWe289kXIRQoj/CQsL44MPPsDT05OjR49SpEiRLLnO8uXLad++PdmzZ+f06dMUKFAgS66jktxEKYQQwM2bNxk4cCAAn3/+eZYVC0Dbtm2pXr069+/fZ/jw4Vl2HZVk5CKEEMAHH3xAWFgY5cqVY//+/bi6umbp9Xbv3k2NGjUwGAzs3buXypUrZ+n1rE1GLkIIh7dt2zbCwsIwGAzMnz8/y4sFoHr16rRv3x5N0wgJCcHevs+XchFCOLTk5GQ+/vhjALp160aNGjWsdu1x48bh4eHBjh07WLVqldWuaw1SLkIIhzZx4kROnjzJSy+9xLhx46x67UKFCjFkyBAABg0a9Nh7amyRlIsQwmGdPn2aMWPGADBt2jS8vb2tnmHQoEH4+/tz8eJFpk6davXrZxVZ0BdCOCRN03jrrbfYunUrDRo0YOPGjcqOY1m2bBkdOnQgR44cnDp1yi62JsvIRQjhkJYtW8bWrVvJli0bc+bMUXrOV9u2balWrRr37t1jxIgRynJYkoxchBAO5/bt27zyyivcuHFDN3fJP7g1ed++fVSqVEl1pBciIxchhMMZOnQoN27coHTp0uYbJ1WrXr067dq1Q9M0+vXrZ/Nbk2XkIoRwKDt27KB27doAhIeHU6tWLcWJ/nb58mUCAwNJTExk1apVvPvuu6ojPTcZuQghHEZKSor5npaPPvpIV8UCGVuTBw0aBNj+1mQpFyGEw5g8eTJHjx4lX758TJgwQXWcRxo8eDB+fn6cP3+e6dOnq47z3GRaTAjhEM6dO0eZMmVISkpi8eLFdOzYUXWkx1qyZAmdOnXCy8uLU6dO4evrqzrSM5ORixDC7mmaRo8ePUhKSqJevXp06NBBdaQnat++PVWrViU+Pt5mtybLyEUIYfe+++472rRpg5ubG4cPH6ZkyZKqI/2rP//8k9deew2DwcD+/fupWLGi6kjPREYuQgi7dvfuXUJCQgAYPny4TRQLQI0aNWjbtq3Nbk2WkYsQwq716NGDuXPnEhgYyKFDh3B3d1cd6aldunSJwMBAkpKS+OGHH2jZsqXqSE9NRi5CCLu1e/du5s2bB8DcuXNtqlgAChcubN6aPHDgQJKTkxUnenpSLkIIuzVkyBA0TaNz587UrVtXdZznYqtbk2VaTAhhl4xGIzly5CAxMZETJ04QGBioOtJzW7x4MZ07d8bLy4vTp0/z0ksvqY70r2TkIoSwS9HR0SQmJuLi4kLx4sVVx3khHTp0oEqVKsTHxzNy5EjVcZ6KlIsQwi6dOnUKgOLFi+Pi4qI4zYtxcnJi2rRpAISGhhIREaE0z9OQchFC2CVTudjK1uN/U7NmTd5//32b2Zos5SKEsEv2Vi4AEyZMwN3dnW3btvHTTz+pjvNEUi5CCLt0+vRpwL7KJSAgwPz8Gb1vTZZyEULYJdPI5eWXX1acxLKGDh1KgQIFOHv2LDNnzlQd57FkK7IQwu6kpqbi4eFBeno6UVFRFCxYUHUki1q0aBHBwcHkzJmT06dPkz9/ftWRHiIjFyGE3Tl//jzp6el4enri5+enOo7FdezYkcqVKxMXF6fbrclSLkIIu/PgYr7BYFCcxvL+uTX50KFDagM9gpSLEMLu2ONOsX+qVasWrVu3xmg06nJrspSLEMLuOEK5wN9bk3///XfWrl2rOk4mUi5CCLtj2oZsbzvF/qlIkSIMGDAAgAEDBuhqa7KUixDC7jjKyAUytib7+vpy9uxZVq1apTqOmZSLEMKu3L9/n6ioKMAxysXLy4sWLVoAcOLECcVp/iblIoSwK2fOnAHAx8eHPHnyKE5jHYUKFQIynlypF1IuQgi74khTYiamcrl8+bLiJH+TchFC2BUpF32QchFC2BVHLJfChQsDGeWil/tdpFyEEHbFUbYhP6hgwYIYDAaSk5O5ceOG6jiAlIsQws444sjFzc2Nl156CdDP1JiUixBP4fbt2xw+fFh1DKv566+/MBqNqmM8s1u3bnHr1i0ASpQooTiNdZmmxvSyY0zKRYinMHLkSCpWrMiUKVNUR8ly3377LTVq1KBXr142VzCmKTF/f3+yZ8+uOI116W1R30V1ACH07uDBg8ybNw+j0UilSpVUx8lyqampaJrG3LlzAZg1axZOTrbxfagjTomZ6K1cbONvjBCKGI1GevbsidFopE2bNrzxxhuqI2W5Tp06ERYWhsFgYO7cuebP3xY4crk8uGNMD2TkIsQTLF26lD///JPs2bMzadIk1XGsplOnTgAEBwczb948AGbPnq37EYwj7hQz0dtd+lIuQjxGbGwsgwcPBuDTTz/F399fcSLrssWCceSRi0yLCWEjPv/8c65fv05gYCAhISGq4yjRqVMnFi1ahMFgYN68efTo0UO3U2Sapjl0uZimxa5cuUJaWpriNGDQ9HI7pxA6cvjwYSpWrEh6ejqbNm2iQYMGqiMptWTJEjp37oymaXTr1o05c+bobgQTHR2Nv78/zs7OJCYm4urqqjqSVRmNRrJly0ZqaioXL140l40q+vrbIYQOaJpG7969SU9Pp2XLlg5fLAAdO3Y0j2Dmz5+vyxGMadRSrFgxhysWACcnJwoWLAjoY2pMykWIf1ixYgXbt2/Hw8PDIe5reVodO3Zk8eLF5oLp3r27rgrGkafETPS0Y0wW9IV4QHx8PAMHDgRg2LBhBAQEKE6kLx06dAAy1mIWLFgAwNy5c3UxRWYqF0fcKWaipx1jUi5CPOCLL77gypUrFC9e3FwyIjNTwXTu3FlXBWPahuzIIxc97RiTchHif06cOMHUqVMBmD59OtmyZVOcSL/+WTCapjFv3jylBSPTYlIuQuiOaRE/LS2Npk2b0qRJE9WRdO/Bgvnqq68AlBVMWloaZ8+eBRy7XPR0eKWUixDA6tWr+fXXX3F3d2fatGmq49iMDh06YDAY6NSpk9KCuXDhAmlpaXh4eJh3TDkiPY1c1K/CCaFYQkIC/fr1A2Dw4MEUL15ccSLb0r59exYvXoyTkxNfffUV3bp1s/ousgcX81Wv/ahkKpebN2+SmJioNIvj/ikI8T9jx47l8uXLBAQEMHToUNVxbNKDBRMaGmr1gpH1lgy5c+c2P2ogKipKaRYpF+HQzpw5Yz6QcurUqXh6eipOZLvat2/PkiVLlBSMbEPOYDAYdLMdWcpFOCxN0+jbty8pKSk0aNCA5s2bq45k89q1a6ekYGQb8t/0su4iC/rCYa1bt44NGzbg6urKjBkzMBgMqiPZhXbt2gEZd/SHhoYCMH/+/CxdC5Fpsb/p5S59KRfhkJKSkujbty8A/fv3JzAwUHEi+/LPgtE0jQULFmRJwSQmJpqngKRc9HOXvpSLcEgTJ07k/PnzFCxYkBEjRqiOY5fatWuHwWCgQ4cOfP311wBZUjDnzp0DIFeuXPj4+Fj0vW2RTIsJociFCxcYN24cAJMnTyZHjhyKE9mvtm3bAmRpwTg7O5v/X6Y29TMtJgv6wuH069ePpKQk6tatS+vWrVXHsXtt27Zl6dKlODk58fXXX9O1a1eLLvLny5cPyHhyaEpKisXe11Y9OC2m8nFd8rAw4VA2btxI48aNcXZ25tChQ5QpU0Z1JIexYsUK2rdvj9Fo5MMPP+Srr76yyAjGaDTi5uZGeno60dHR+Pn5WSCt7UpISDDf63Lnzh28vb2V5JCRi3AYycnJ9OnTB4A+ffpIsVhZmzZtWLZsGU5OTnzzzTcWG8E4OTmZ11pu3Ljxwu9n6zw9Pc2/HyqnxqRchMOYOnUqp0+f5qWXXuLzzz9XHcch/bNgPvroI4sUjGlqTMolgx52jEm5CIcQFRXFF198AcCkSZPImTOn4kSOq02bNixfvhwnJycWLlxokYKRcslMDzvGZLeYcAgDBgwgISGBWrVqmY+KF+q8//77QMZ25YULFwIQGhr63GswUi6ZSbkIYQW//fYbK1euxMnJiVmzZsl2VZ0wFUz79u1fuGCkXDLTw3NdpFyEXUtNTaV3794A9OjRg/LlyytOJB5kqYKRcslMRi5CZLGZM2dy7Ngx8uXLx+jRo1XHEY/wz4LRNI3Q0NBMN0f+GymXzPRQLrKgL+zW1atXzbvCxo8fT+7cudUGEo/1/vvvs3z5cpydnQkLC+Ojjz4iPT39qX+9lEtmpmmxqKgoqz+4zUTKRditwYMHEx8fT9WqVQkODlYdR/yL1q1bP3fBSLlk5ufnh8FgICUlhZiYGCUZpFyEXQoPD2fp0qUYDAZmz57t0I++tSX/LJgePXo81a+TcsnM1dWVAgUKAOqmxuRfnLA7aWlp9OrVC4CuXbtSpUoVxYnEs2jdujXffvstTk5OLFiwgO3bt//rrzGVy+3bt59pOs2eqT7AUspF2J158+YRGRlJnjx5GDNmjOo44jm89957dOvWDci4R+nf1g1Mx51omsatW7eyPJ8tUH2XvpSLsCsxMTHm57OMGTOGvHnzKk4kntfnn3+Ol5cX+/fvZ/ny5U98rYuLC3ny5AFkasxE9Y4xKRdhVz755BNiY2OpVKkSXbt2VR1HvID8+fMzbNgwIOPPNSEh4Ymvl3WXzGRaTAgL2b17N9988w0As2bNeqb7JIQ+hYSEULhwYaKiopg6deoTXyvlkplMiwlhAenp6eZF/ODgYGrUqKE4kbCEbNmymZ8aOn78eK5du/bY10q5ZCbTYkJYQGhoKPv37ydXrlyMHz9edRxhQW3atKFq1arcu3ePzz777LGvk3LJzDQtdvXqVVJTU61+fSkXYfNu3bplnpsfPXo0L730kuJEwpKcnJyYMmUKkPFNxJEjRx75OimXzPLly4ebmxuaphEdHW3160u5CJs3YsQIbt++Tbly5Z76pjthW2rWrMm7776L0Whk4MCBj3yNlEtmTk5O+Pv7A2qmxqRchE3bv38/8+fPBzIW8V1c5CxWezVhwgRcXV3ZtGkTmzZteujnpVwepnLdRcpF2Cyj0UivXr3QNI127dpRp04d1ZFEFipevLh508bAgQMfuhNfyuVhKrcjS7kIm7Vo0SJ2795Njhw5mDRpkuo4wgpGjhxJnjx5OHLkiHnbuYnphlm5Q/9vKrcjS7kIm3T37l2GDBkCwGeffYafn5/iRMIacufOzaeffgpkrLXFx8ebfy5XrlwAxMXFKcmmRzItJsQz+vTTT7lx4wavvPIKffr0UR1HWFH37t0pUaIEMTExTJgwwfxxLy8vAO7fvy+HV/6PTIsJ8QwiIyOZPXs2kPGkSTc3N8WJhDW5ubkxceJEACZPnmz+wpkzZ07za+7du6ckm97ItJgQT0nTNHr16oXRaKRVq1a8+eabqiMJBZo3b06dOnVISkpi+PDhALi7u5u/0ZCpsQymcrl9+/a/ns1maVIuwqYsX76c8PBwPD09mTx5suo4QhGDwWD+81+yZAn79u0D/p4ak3LJkCtXLvPvibWnxqRchM2Ii4sz30A3fPhw83xyVrt58ybh4eFommaV69my69evW21KqkqVKnTo0AHIeOaLpmnmqbEHF/odmcFgUDY1JuUibMbo0aO5du0aJUqUYMCAAVa7bmhoKHXq1CEoKIg5c+bId8WPcfnyZYoWLcq7775rtWuOHTsWd3d3/vjjDw4fPmwuF/kz+puqHWNSLsImHDt2jOnTpwMwY8YM3N3drXbthIQEPDw8OHLkCD179qRgwYJ0796dyMhIq2WwBXv37iUxMZEtW7Zw9+5dq1yzUKFC1KtXD4BNmzbJtNgjqNoxJuUidE/TNHr37k1aWhpvv/02jRs3tur1R48ezZUrV5g2bRqBgYHcu3ePefPmUb58eWrVqsWyZctITk62aiY9OnfuHJDx57V7926rXbdhw4ZARrnItNjDZFpMiMdYtWoVv/32G+7u7kybNk1JBm9vb/r27cvx48fZunUrrVq1wsXFhZ07d9KhQwf8/f0ZOnQo58+fV5JPDx783Hfu3Gm165rKxbTRA2Tk8iCZFhPiEe7fv0///v0BGDp0KEWLFn3i6xMTE9mwYQMjR47MkjwGg4F69erx/fffc/HiRUaNGkXBggW5efMmEyZMoHjx4jRp0oR169Y53I18ppELWLdcAgMDKVy4MCkpKebNBFIuf1N2l74mhI598sknGqAVKVJES0hIeORroqKitPnz52vNmjXTPDw8NEADtJMnT1olY2pqqrZ69WrtrbfeMl8b0AICArSxY8dq169ft0oO1QIDA82fu6enp5aSkmK1a3ft2lUDtEqVKmmANmjQIKtdW+9OnTqlAVr27Nk1o9FotetKuQjdOnnypObq6qoB2po1a8wfT09P13bv3q2NGDFCq1ChQqYv6IBWqFAhrXv37tqZM2esnvnUqVNa//79tdy5c5vzuLq6am3bttX++OMPq/7jtqb09HTNzc1NAzRnZ2cN0Pbu3Wu163///fcaoOXNm1cDtG7dulnt2nqXkJBg/rt469Ytq11XykXoktFo1Bo1aqQBWuPGjTWj0aj98ssvWnBwsJY/f/5MZWIwGLQaNWpoY8aM0Q4dOqSLL+AJCQnawoULtapVq2bKWrZsWW327NlabGys6ogWFRUVZS6WBg0aaIA2bdo0q13/9u3bmpOTk/n3uW3btla7ti0wlW5ERITVrinlInRpzZo1GqC5ublpp06d0hYvXpzpi3TOnDm11q1ba4sXL9ZiYmJUx32iffv2aV26dMk0ZZcjRw7t448/1g4dOqQ6nkX88ccfGqAVLVpUGzNmjAZo7733nlUz1KhRw/z727RpU6teW+9M04U///yz1a4pC/pCdxITEwkJCQEy7rzOmzev+abJtm3b8ttvv3Hz5k2+++47OnbsaH5IlF5VrlyZ0NBQoqOj7XY7s2mnWLFixahZsyaQsaivWfFUA9OuMZAF/X9SsR1ZykXozoQJE7hw4QL+/v4MHz6c4cOHc+PGDUqVKkVYWBh169bF1dVVdcxnljt37iduZy5UqJDNbmc2fdEKCAjg1VdfxcXFhStXrnDx4kWrZXiwXGJjY612XVugYseYlIvQlXPnzjF+/HgApkyZwvHjx5k3bx4Ac+bMsYvj9R+3nfnGjRs2u505LS0NgGzZsuHp6UmlSpUA625JrlKlCjly5AAyzoMTf1Nxl76Ui9CVfv36kZycTP369WnRogU9evRA0zTat2/PG2+8oTqexfn5+fHpp59y4cIFVq9ezVtvvYWmaWzYsIFmzZpRvHhxxo0bR0xMjOqoT2QwGAAwGo0AmabGrMXFxYUaNWoAcOfOHatd1xbItJhwaBs2bGDt2rW4uLgwc+ZMQkND2bt3Lzlz5uT//u//VMfLUi4uLrRo0YLNmzdz6tQp+vfvT+7cubl48SLDhg3D39+fdu3asWPHDl2ezuzklPGlxJRNRbkA1K9fH8hYtxN/k2kx4bCSk5Pp27cvACEhIfj4+DBs2DAAvvjiC3x9fVXGs6qXX36ZyZMnEx0dzcKFC6latSqpqal8++231K5dW5enMz9u5HL48GGrrn/85z//ATJK7vr161a7rt6Zfi88PDysdk0pF6ELkydP5syZMxQoUICRI0cyZMgQ7ty5Q4UKFejRo4fqeEp4eHgQHBzMnj172LdvH126dNHt6cz/HLn4+vpSrFgxqx9iWapUKfP/b9iwwWrX1buNGzcC0KBBA6tdU8pFKHfp0iW+/PJLACZNmsSZM2cICwsDMhbxXVxcFKbTB71vZzaVi2nkAurWXUx/XzZt2mS16+qZpmnmcmnUqJHVrivlIpQbMGAAiYmJ1K5dm3bt2pm/GDVu3Ni8QCsy6HU7s2la7MH1IFXrLqZnumzbtk2X61PWdvz4cS5fvky2bNl4/fXXrXZdKReh1K+//sqqVatwdnZm1qxZGAwG8zbSgIAAxen062m3M69fv94q25mfNHLZs2ePeauyNfj4+AAZ6wwnTpyw2nX1yjRqef3112XNRTiGlJQUevfuDUDPnj0JCgoC/r5HQe933uvFk7YzN23a1Crbmf+5oA9QunRpvL29uX//PocOHcqya/9Trly5zP+/efNmq11Xr1RMiYGUi1BoxowZnDhxgvz58zNq1Cjzx2/cuAFA3rx5VUWzSSq3M/9zQd/0MdO0pjWnxkw3UoKsu9y/f5/t27cDUi7CQVy5csVcKBMmTMDb29v8c6aRi5TL83ua7cxz58612OOAHzUtBn9Pje3atcsi13kazs7O5v/ftm0bSUlJVru23mzfvp2UlBQCAgIIDAy06rWlXIQSgwYN4t69e1SvXp1OnTpl+jnTyEWmxV7ck7Yz9+jRAz8/P4tsZ37Ugj78XS7h4eFWP8rG29ubxMREduzYYdXr6smDU2KmPyNrkXIRVrd9+3aWL1+OwWBg1qxZ5u96TWTkkjWycjvz40Yu1apVI3fu3Fy5coWvv/7aIp/H0ypXrhzg2FNjqtZbQMpFWFlaWhq9evUCoFu3blSuXDnTz2uaJgv6WexR25mdnZ1faDvz40YuHh4efP755wAMHz6cu3fvWurT+Ffly5cHHHdR/+zZs5w+fRoXFxfq1atn9etLuQirmj17NkeOHCFPnjzmGycfFBsba962atpSKrLGg9uZL1269ELbmR83cgHo3r07pUqV4ubNm4wePTpLPpdHKVeuHAaDgcjISK5evWq16+qFacRWs2ZNcubMafXrS7kIq7l+/TqffvopAOPGjXtkeZhGLdmzZ7fqnnxH96LbmZ9ULq6urkydOhWAmTNnWu3eEy8vL/PI2BFHLyqnxEDKRVjR0KFDiYuLo3LlynTp0uWRr5HFfLWedzvz46bFTBo2bEizZs1IS0ujf//+VvlcTNcFx1t3SU5O5rfffgOkXISd+/PPP83nhc2ePTvTdtEHyWK+fjzLduYnjVxMJk+ejKurK7/88ovVDpU0HdS4ZcuWJ2azNzt37uT+/fv4+vqa156sTcpFZLn09HR69uwJwIcffki1atUe+1rTPQnu7u5WySb+3dNsZ54/fz7w+JELZJRVSEgIkPFQuJSUlCzPXqNGDby8vLh58yYHDhzI8uvphWlKrGHDhlbfgmwi5SKy3IIFCzh48CDe3t6MGzfuia/18/MDIDo62hrRxDN63Hbm/fv3A08euQCMGDGC/Pnzc+rUKWbNmpXleV1dXc07pRxp3UX1egtIuYgsdvPmTYYPHw5kPPQrf/78T3y96Yl50dHRDjWNYWsedzrza6+99sRflzNnTvM3GKNGjbLK45sdbd0lOjqaw4cPYzAYeOutt5TlkHIRWWrYsGHcuXOHoKAgPv744399vZ+fH05OTqSmpsqTBG3Ag9uZk5OT+eSTT/711wQHB1O5cmXi4uIYMWJElmc0lcuuXbt09fTOrGIq0apVqyrdzi/lIrLM3r17CQ0NBTIW8Z/moV8uLi7mqbFLly5laT5hWf88aeFJr5s+fToAoaGhHDx4MCtjUaxYMYoXL05aWhq///57ll5LD/QwJQZSLiKLGI1GevXqhaZpdOjQgVq1aj31rzVNjV2+fDmr4gnFatasSdu2bdE0jb59+2b5Q70cZWosLS2NLVu2AFIuwk4tXLiQv/76Cy8vLyZOnPhMv7Zw4cKAlIu9mzBhAh4eHoSHh/P9999n6bVM5WLvi/p//fUXd+/eJXfu3Lz66qtKs0i5CIu7c+cOQ4cOBeDzzz+nQIECz/TrTSMXmRazb6YzzCDjlOyEhIQsu1bdunVxcXHh7NmznD17Nsuuo5ppSqxBgwaPvZfMWqRchMWNHDmSmzdvUrp0afOTJp+FTIs5joEDB1K4cGEuXbrE//3f/2XZdby8vMzH/9vz1Jhe1ltAyiVLXLhwgRMnTnDv3j3VUawuIiKCuXPnAhnnSLm6uj7ze8i0mOPw9PRk0qRJAIwfPz5L/8ztfd3lxo0b7Nu3D/j7c1VJyiULtGrVilKlShEeHq46ilVpmkavXr0wGo20bt36uY/5lmkxx/Lee+9Ru3ZtEhMTGTJkSJZdx3QUzG+//WaV0wGsbcuWLWiaRvny5Z95KjorSLkIi7h58yZff/01O3fuxNPTk8mTJz/3e5lGLteuXePkyZOWiih0ymAwMH36dAwGA99++22WPTmyYsWK5MuXj3v37rF79+4suYZKepoSAykXYQEXLlygRo0a5vPDRo4cib+//3O/34OHVh47duyF8wn9q1ixIh999BEAffv2zZLTGZycnMx3rNvb1JjRaDR/TlIuwi5ERkby2muvcebMGVJSUihatCj9+vV7ofc0GAx88803DB8+nHfeecdCSYXeffnll+TMmZMDBw6YT9C2NHtdd4mIiCAmJoYcOXL86xE81mLX5aJpGqmpqapj2K3w8HDq1KmT6Sl/c+fOtciJxh988AFffvnlU9/1LWxf/vz5+eyzzwD45JNPiI2Ntfg1TCOXAwcOmJ8dZA9MU2L169fHzc1NcZoMdv0v9/jx4+TLl48uXbpk+R3Ajuann36iQYMGxMbGkitXLgCaN2+ui10qwnb16tWLkiVLEhMT88jHYL+oAgUKEBQUhKZp5jvZ7YHe1lvAzsvlxx9/JDY2luvXryt5poG9FlpoaCgtW7YkKSmJypUrExsbS7Zs2cyPshXiebm5uZn/Hk2fPp1Tp05Z/Br2drd+bGwsu3btAvSxBdnErstl9erVALRo0UJxEvugaRpjx46la9euGI1GOnXqZJ4S++STTyhSpIjagMIu/Oc//6Fx48akpqYyYMAAi7//g+ViD98Abt26lfT0dAIDAylatKjqOGZ2Wy4XL17kwIEDODk58fbbb1v12qqe/JaVjEYjISEh5mezDBs2DF9fX65cuUKxYsUYPHiw4oTCnkyZMgUXFxfWrVtnnvKxlFq1auHp6cnVq1c5fPiwRd9bBdMjo/U0JQZ2XC4//vgjALVr1yZfvnyK09i2lJQU2rdvz4wZM4CM6YpOnTqZpy+mTZtGtmzZVEYUduaVV14xHx3Ur18/i27McXd354033gBsf9dYfHw8K1euBKBZs2aK02Rm9+UiU2IvJj4+niZNmrBixQpcXV359ttv6d27N7179yY1NZUmTZro7i+1sA+ffvopefPm5cSJE8yZM8ei720vW5KXLFlCfHw8gYGB1K1bV3WcTOyyXGJiYsx3+TZv3lxtGBt248YN6tWrx6+//kr27NlZv349bdq0Yc2aNWzZsgU3NzemTZumOqawU97e3owZMwaAzz77zKJbh01HwYSHh3P//n2Lva81aZrGrFmzgIxddnrbtq+vNBaydu1ajEYjlStXJiAgQHUcm3ThwgVq1qzJvn37yJs3L7///jtvvfUWCQkJhISEABnHpJcoUUJtUGHXunTpQvny5YmNjeXTTz+12PsGBgZSuHBhUlJS+OOPPyz2vtb022+/cfz4cXLkyEGnTp1Ux3mIXZaLTIm9GNNd96dPnyYgIICdO3eaHzw0fvx4Ll26ROHChRk2bJjipMLeOTs7mx+JvGDBAg4dOmSR9zUYDDY/NWYatXTu3JmcOXMqTvMwuyuXuLg4fv31V0BduXh5eQHY5E6UP/74w3zXfbly5di1axclS5YE4Pbt2+anSk6ZMgVPT0+VUYWDeP3113nvvffMOxYttX3Ylsvl4sWLrF27FsB8pp/e2F25bNiwgZSUFAIDAylVqpSSDB07dgQynmdiS8fPrFmzxnzXfe3atfnjjz/w8/Mz//zKlStJTk4mKCiIli1bKkwqHM3EiRPJli0b27ZtM9+/9qLq16+Ps7MzJ06csLnHO8ybNw+j0Uj9+vWVfZ37N3ZXLg/eOKnqfpN27drh6+tLdHS0eZug3oWGhvLuu++SnJzMO++8w6ZNm/D29s70msWLFwMZw3B7vJdH6FeRIkUYNGgQkPH0ysTExBd+T29vb6pVqwbY1uglKSmJr776CuC5nvRqLXZVLklJSfzyyy+A2vUWd3d3evXqBcDkyZN1fRewpmmMGTPGfNd9ly5dWLVqFR4eHpled/r0af7880+cnJxo166dorTCkQ0ZMoSCBQty4cIFpkyZYpH3NO0as6WjYFasWMGtW7coXLgwTZs2VR3nseyqXH799Vfu3buHv78/VapUUZrl448/xsPDg4MHD7J9+3alWR7HaDTSp08fRowYAcDw4cP56quvcHFxeei1S5cuBTL+Mfr6+lo1pxAA2bNnN6/5jR07lrNnz77we5rWXX799dcseYaMpWmaxsyZMwHo0aMHzs7OihM9nl2Vi2lKrHnz5sr3fPv4+BAcHAzwQk9lzCrJycm0a9eOWbNmYTAYmDFjBl9++eUjp7uMRqN5SkyPWx6F42jbti21atUiISGBRo0aERMT80LvV6lSJQDu3r3L7du3LRExS+3Zs4cDBw7g7u5Oly5dVMd5IrsplytXrrBmzRpAP1uQQ0JCMBgMrFu3jhMnTqiOYxYfH0/Tpk357rvvcHV1Zfny5U+cu925cycXLlzAy8tLHt4llDIYDKxcuZKAgADOnDlDkyZNuHfv3nO/n5ubGz4+PgCZnkukV6btx23bts30xFY9sotyiY+Pp2DBgty5cwfAfE+GaiVLljQfjaKXO9ljYmKoW7fuQ3fdP8mSJUsAaNWqlWw/FsoVKFCATZs24ePjw759+2jVqhUpKSkv9H6g/3K5fv26eYOQnhfyTR6eXLcxKSkpD91ANG3aNEaOHKkoUWYDBgxg7dq1LFq0iC+++ELpIZrnz5+nQYMGnDlzhrx58/LLL7/869pUUlKS+S90+fLlmTFjBocOHeLy5csWzWbJ3WdDhw7V3TlLwrICAwNZv3499erVY9OmTXTp0oVFixY913R4gQIFOHLkiO7LZcGCBaSmplKjRg3zdJ6uaTZu4MCBGqABmpOTkwZonp6e2uXLl1VH0zRN04xGo1alShUN0EaNGqUsR0REhObr66sBWkBAgHby5MlHvs5oNGrnzp3TVq9erX322Wfm7Lb0Y/ny5Vb+3RWqrF+/XnN2dtYAbdCgQZqmaVq9evWe6e9Bp06dNEAbN25cVkZ9ISkpKZqfn58GaMuWLVMd56nY/MjFdLbVO++8w48//kjt2rXZuXMnQ4cONe9wUslgMNC/f3/atWvH7NmzGTx4sNWPp9++fTtvv/02cXFxlCtXjo0bN+Ln50diYiJHjx7l0KFDREREcOjQIQ4dOkRcXNwj36dw4cJUqFCB8uXLU6JECYvtVNEsvFW7evXqFn0/oV//+c9/CA0N5YMPPmDSpEnmKa5nYdr9eO3aNUvHs5g1a9Zw5coVXnrpJVq1aqU6ztNR3W6WYDQazf+/b98+zWAwaIC2a9cuhan+lpKSohUqVEgDtJo1a2qhoaHanTt3rHLt1atXa+7u7hqglS1bVvv888+1du3aaaVLlzZ/x/fPH25ublrFihW1Nm3amH8vd+/ebZW8QjyPcePGmf/+lilT5plGLlOnTtUArXXr1lmc8vnVqVNHA7SRI0eqjvLU7KJc/unDDz/UAO3VV1/V0tPTVcfRNE3Tli5dav5CbfoC3qJFC23VqlVaYmKixa6TlpamHTt2TFu+fLnWsGHDf51C8vHx0erXr68NGDBAW7x4sRYZGamlpKRomqZp06dPN/8+CqFnRqNR6927twaY/509bbmsWLFCA7TatWtnccrnc+jQIQ3QXFxctOjoaNVxnppdlsvVq1c1Ly8vDdDCwsJUxzE7f/68NnbsWPN3VqYfuXLl0j788ENt69atWlpa2lO/X1xcnLZjxw5t1qxZWteuXbVXX31V8/DweGyRlCxZUmvdurU2ZswYbf369VpUVFSmUd8/Va5cWQO0mTNnWuLTFyJLpaena61btzb/fR87duxT/brt27drgFaiRIksTvh8unbtqvuR1aPYZblomqZNnDhRA7R+/fqpjvIQo9GoRUREaIMGDdL8/f0zFYCfn582YMAA7cCBA+Yv/EajUbt48aL2008/aaNHj9ZatmypFS9e/LEl4uLiYv7/xo0ba7t27dLu3bv3TBmPHj1qfq8bN25kxW+DEBaXlJSkeXt7a4CWM2dO7ezZs//6a06dOqUBWo4cOayQ8Nncvn3b/A3jH3/8oTrOM7HbcklKSrKJdYL09HTt999/17p27Wr+R2H6kSdPHq1IkSLmUdijfvj7+2tNmjTRhg8fri1btkxr3LixeWpgxowZz51r6NChGqC9/fbbFvxshch6pvUJ02jk+vXrT3x9XFyc+fXx8fFWSvl0Jk+erAFaUFDQE2cZ9Mjmd4s9jru7u/nEU726efOmeadWUlISBQsWJC4uznzG0e3btzMdSeHn50etWrWoVq2aedeW6e7i+Ph4WrRowdatW3F1dWXx4sX/enPk4xiNRvNOO9PjA4SwFaaz8fLmzWu+i//3338nR44cj3y9l5cX2bNn5/79+1y9epWXX37ZmnEfy2g0Mnv2bCDjpklbO4ncbstFT9LT0zl79qx5u6/pv9HR0Y98fe7cuSlbtizZsmXjypUrHD9+HKPRyJUrV/jhhx+4d+8evr6+5vKMiYmhcePGHDhwgOzZs/Pjjz/y1ltvPXfebdu2ERUVhbe3t65PXRXiST755BPGjRtnvot/7dq1uLm5PfK1BQoU4MyZM7oql19++YVz587h7e1tkyeRS7lY2L179zh8+HCmEomMjCQhIeGRry9evDgVKlQwj0QqVKiAv79/pu9Srl69yooVK1i2bBn79+9nw4YNbNiwAU9PT5o3b85ff/31THfd/xvTIZXvv/++1e/JEcJSChQowLp1657qLn5TuejpXhfTOWJdunSxyWOXpFyek6ZpXLlyhYiIiEwjkjNnzjzypkAPDw/KlStnLpDy5csTFBRkfiTykxQoUIB+/frRr18/Tp48ybJly1i+fDlnz55l+fLlQMbDlDZt2mR+JPGLfF4bNmwAsMnvloR4ULVq1Vi1ahXNmjVj6dKlFChQwHxs/4NMN1Lq5QiY06dPs3HjRgwGA927d1cd57lIuTyF1NRUjh8/nmk0EhERwa1btx75+gIFCmQqkQoVKvDyyy9b5I72wMBARo8ezahRo/jrr79YtmwZMTExTJkyJdMjiZ/XxYsXuXHjBq6urrpfsxLiaTRu3Jivv/6a4OBg8138/fr1y/QavR1eOWfOHCDjBILixYsrTvN8pFz+4c6dOw+VyLFjxx556qqzszOvvPJKphIpX748+fPnz/KcBoOBatWqWbwA9u7dC0BQUBDu7u4WfW8hVOncuTNXr17lk08+oX///hQoUCDThhc9lcu9e/dYuHAhYBunHz+Ow5aL0Wjk/PnzDy2yX7p06ZGvz5kz50MlUqZMGbtbkzCVi14eWyCEpQwZMoSrV68yY8YMOnXqRN68eXnzzTcBfZXL0qVLiY2N5eWXX36hjTmqOUS5JCQkcOTIkYcOaHzcQ4aKFi360LRWQECAzW0FfB6mclH9mGghnlebNm149dVXKVWqVKaPGwwGpk6dyrVr11i5ciWtWrXi3Llz5MmTx1wuqhf0NU0zL+T37NlT+RN1X4Tdlcu1a9ceWmQ/derUI5+P7e7uTtmyZTOVSFBQELly5VKQXD2j0cj+/fsBGbkI29W1a9fH/pyTkxOLFy8mPj6eDz74gDx58gD6WdDfvn07R48eJXv27HTu3Flplhdls+WSlpbGyZMnH5rWetwztfPnz//QtFZgYKD5hisBJ0+eJD4+Hg8PD0qXLq06jhBZwt3dnfXr12eaiTCNXG7evElKSspj74fJaqZRS8eOHfH29laSwVJs4itrbGwskZGRmYrkyJEjJCcnP/RaJycnAgMDH5rWMn1nIh5v3759AFSqVElKV9i1f05x+/j44OLiQlpaGtevX6dQoUJWz3T58mXWrFkDQK9evax+fUvT7VeQX3/9lTlz5hAREcH58+cf+RovLy+CgoIylUiZMmVs8oYjPZDFfOGonJyc8PX1JSoqimvXrikpl3nz5pGenk7dunUpU6aM1a9vabosl2+++YauXbtmWid58CmIpv8WLVrUphe89EbKRTiyAgUKEBUVpWTdJSkpiQULFgD2MWoBnZWLpmlMmDCBTz75BID27dvz0UcfERQUZF54E1kjNTWViIgIQMpFOCaVi/rff/89N2/exN/fn7ffftvq188KuikXo9HIgAEDmDZtGgBDhw5l7NixDrH9Vw+OHDlCUlIS3t7elChRQnUcIaxO5b0upoX87t272816py4+i9TUVD744AOWLVsGwJQpUx46nkFkrQfvb5FCF45I1b0uf/31F3/99Rdubm5P3EZta5SXy/3792nVqhUbN27ExcWFhQsX0qFDB9WxHI6stwhHp2rkYhq1tGnThnz58ln12llJabncunWLJk2asGfPHjw9PVm1ahWNGzdWGclhyZ35wtGpWHOJiYnhu+++A+xnId9EWblcvnyZhg0bcvz4cfLkycP69eupXr26qjgOzXQ8DsjIRTguFSOX0NBQUlJSqFq1qt3921NSLseOHaNhw4ZERUXh7+/P5s2bHzoHSFhPREQE6enpvPTSS/j7+6uOI4QSD665GI3GLL/NIS0tjblz5wK2ffrx41j9JpGoqChq165NVFQUpUqVYteuXVIsij243iKL+cJRvfTSS0DGF/3bt29n+fV++uknoqKiyJcvH++9916WX8/arF4uoaGh3L59m6CgIMLDw5XcCSsyk8V8IcDNzY28efMC1pkaMy3k//e//7XLZydZtVw0TWPJkiVAxrMVfHx8rHl58RimM8WkXISjs9ai/pEjR9i2bRvOzs5069YtS6+lilXLZdeuXZw7d44cOXLQvHlza15aPEZsbCwnT54EpFyEsNai/uzZswFo3ry53c7eWLVcFi9eDECrVq3kcEmdMD2/pUiRIuYpASEclTVupLx+/br5a6E9LuSbWK1ckpKSzPu5O3bsaK3Lin8h6y1C/C2rRy5Go5FOnTqRkJBApUqVqFOnTpZcRw+sVi4bN24kNjaWQoUK8cYbb1jrsuJfSLkI8TfTHfI3b97MkvefPHkymzdvxsPDgyVLltj17kyrlculS5cAqFGjhhyTryNyZ74Qf3N2dgYyNh9Z2p49exg2bBgAM2bMsPunvVr9q7w9N7WtiYmJ4dKlSxgMBipXrqw6jhB26+7du7Rp04a0tDTef/99unTpojpSlpMhhAMzjVoCAwPJmTOn4jRC2CdN0/jvf//LhQsXKFq0KPPnz3eIb7KlXByYrLcIkfVCQ0P5/vvvcXFxYcWKFeTKlUt1JKuQcnFgUi5CZK2jR4/Sp08fAMaNG0fVqlUVJ7IeKRcHZjoJuVKlSoqTCGF/EhISeP/990lKSqJRo0b0799fdSSrknJxYCkpKQDkyJFDcRIh7E+/fv04evQovr6+LFq0yOF2yTrWZyuEEFawcuVKFixYgMFgYOnSpeTPn191JKuTchFCCAs6f/48Xbt2BWDYsGHUr19fcSI1pFyEEMJCUlNTadOmDXFxcdSsWZPPP/9cdSRlpFyEEMJCRowYwV9//YW3tzfLly/HxUXZk+SVk3IRQggL2LRpExMnTgTgm2++oXDhwooTqSXlIoQQL+jatWt06tQJgB49etCiRQvFidSTchFCiBdgNBrp2LEjMTExBAUFMXnyZNWRdEHKRQghXsDEiRP59ddf8fT0ZMWKFWTLlk11JF2QchFCiOf0559/MmLECABmzZpFqVKlFCfSDykXIYR4Dnfu3KFt27akp6fTrl07goODVUfSFSkXIYR4Rpqm0bVrVy5evEjx4sWZO3euQxyj/yykXIQQ4hnNnz+fH374AVdXV1asWCHPQ3oEKRchhHgGkZGRhISEADBhwgR5RPhjSLkIIcRTun//Pm3atCE5OZkmTZqYS0Y8TMpFCCGeUt++fTl+/Dh+fn4sXLhQ1lmeQMpFCCGewrfffsvXX3+NwWBg2bJl5MuXT3UkXZNyEUKIf3H27Fm6desGwMiRI3njjTfUBrIBUi5CCPEEcXFxtGnThvj4eGrXrs3IkSNVR7IJUi5CCPEIBw8epFu3bvj5+bFv3z5y587NsmXLHPoY/Wchv0tCCPE/KSkpQMbx+cuXLzd/vFSpUsydO5dChQqpimZzpFyEEA7vxIkTzJ8/n/nz5wNw69YtXF1deffdd+nevTu1a9eWnWHPSMpFCOGQUlJSWLNmDXPnzmXbtm2Zfq58+fJs3ryZ/PnzqwlnB6RchBAOJTk5mVGjRvH1118TExMDgJOTE02bNsXX15cFCxZQpkwZKZYXJAv6QgiH4ubmxs8//0xMTAwFChRg5MiRXLhwgZ9++kmOzLcgGbkIIRyKwWBg3LhxJCcn8/bbb+Pq6qo6kl2SchFCOJymTZuqjmD3ZFpMCCGExUm5CCGEsDgpFyGEEBYn5SKEEMLipFyEEEJYnJSLEEIIi5NyEUKIf9A0TXUEmyflIoQQ/yCHVL44KRchhBAWZ7VycXd3BzKOshb6IlMAQghLs1q51KpVC4Dw8HDu379vrcuKJ8ibNy8Ap0+fVpxECGFvrFYupUuXJiAggOTkZH777TdrXVY8wZtvvglkPHVPCCEsyWrlYjAYaNKkCQDr16+31mXFEzRs2BDIKBeZGhNCWJJVF/QfLBf5YqZenTp1cHd3JyoqiuPHj6uOI4SwI1Ytl7p16+Lh4UFUVBSHDx+25qXFI3h6elKnTh1ApsaEEJZl1XLx8PCgXr16gEyN6cWDU2NCCGEpVr/PxfSQHikXfTCVy/bt20lKSlKcRghhL6xeLv/5z38A+PPPP+WeFx0oU6YMfn5+JCUlER4erjqOEMJOWL1cChcuTLly5TAajWzcuNHalxf/YDAYaNCgASBTY0IIy1Fy/ItsSdYXWXcRQlia0nLZuHEjaWlpKiKIB7z11lsYDAaOHDlCdHS06jhCCDugpFyqV69O7ty5uXPnDrt371YRQTzAx8eHKlWqALB582bFaYQQ9kBJubi4uNCoUSNApsb0QqbGhBCWpOzIfVl30RdTuWzZsoX09HTFaYQQtk5ZuTRq1AgnJycOHz7MpUuXVMUQ/1OtWjVy5szJ7du32b9/v+o4Qggbp6xcfHx8qF69OgAbNmxQFUP8j6urK/Xr1wdk3UUI8eKUPolSpsb0Re53EY4uNTVVdQS7obRcTEfBbN26lcTERJVRBH+vu/z555/ExsYqTiOE9R08eBCAkiVLKk5i+5SWS7ly5fD39ycxMZFt27apjCKAokWL8vLLL5Oeni4PdBMOaceOHQDUrl1bcRLbp7RcHnyA2Lp161RGEf8jW5KFo7p48SKXL1/GxcWFatWqqY5j85SWC8gDxPTGVC4bNmyQ0xOEQzEd3FqpUiWyZ8+uOI3tU14u9erVw93dnYsXL3Ls2DHVcRxevXr18PHx4fLly3z//feq4whhNTIlZlnKyyV79uzUrVsXkF1jeuDp6UlISAgAY8aMwWg0qg0khJWYRi61atVSnMQ+KC8XkC3JetOrVy9y5szJ0aNHWbt2reo4QmS5W7dumWdOpFwsQ1flsnPnTnmAmA54e3vTq1cvIGP0Imthwt7t3LkTgFKlSpE3b17FaeyDLsqlaNGiVKhQgfT0dObNm6c6jgBCQkLw9PRk3759cse+sHsyJWZ5uigXgIEDBwIwbdo0EhISFKcR+fLl47///S+QMXoRwp6ZykUW8y3HoOlkziMtLY2SJUty/vx5pk+fTp8+fVRHcnjR0dEUK1aMlJQUtm/fTp06dVRHEsLiEhISyJUrF2lpaZw/f54iRYqojmQXdDNycXFxYciQIQBMmjSJlJQUxYlEwYIF+eCDDwAZvQj7tWfPHtLS0ihYsCABAQGq49gN3ZQLQOfOnfH19SUqKoply5apjiOAIUOG4OzszObNm9m7d6/qOEJY3INTYgaDQXEa+6GrcsmWLRsDBgwAYPz48fLQKh0oWrQo7du3B2T0IuyT3DyZNXSz5mISHx9PQEAAd+7cYeXKlbz33nuqIzm8EydOULp0aTRNIzIyknLlyqmOJIRFpKWlkTt3bu7du8ehQ4cICgpSHclu6GrkAuDl5UXv3r0BGDdunNxjoQOvvPIKrVq1AmDs2LGK0whhOREREdy7dw9vb2/Kli2rOo5d0V25APTp04fs2bNz8OBBOZ1XJ4YNGwbAypUrOXXqlOI0QliGaUqsZs2aODnp8suhzdLl76aPj4/5Hotx48YpTiMAKlSoQNOmTTEajYwfP151HCEsQm6ezDq6W3MxiY6OpmjRoqSmphIeHi5/+Dqwe/duatSogYuLC2fOnJFtm8KmaZrGSy+9xI0bN9ixYwc1a9ZUHcmu6HLkAhn3WAQHBwMyetGL6tWrU69ePdLS0pg0aZLqOEK8kNOnT3Pjxg3c3d2pUqWK6jh2R7flAjB48GCcnJzYsGEDERERquMIYMSIEQCEhoZy9epVxWmEeH6mM/OqVq2Ku7u74jT2R9flUqJECVq3bg0g8/w68cYbb1CjRg2Sk5OZMmWK6jhCPJfExETz1xTTTkhhWbpdczGJjIykfPnyODk5ceLECV5++WXVkRzehg0baNKkCdmzZ+fixYv4+PiojiTEM5k0aRKDBw+mcOHCnDx5kmzZsqmOZHd0PXIBCAoKokmTJhiNRiZOnKg6jgAaN25MxYoVuX//PtOnT1cdR4hncvfuXfM67ujRo6VYsojuRy4Au3btombNmri6unLu3Dn8/f1VR3J4q1at4r333sPb25sLFy6QK1cu1ZGEeCrDhg1j3LhxlClThkOHDuHs7Kw6kl3S/cgF4LXXXuP1118nNTVV5vl1omXLlpQqVYq7d+8yZ84c1XGEeCpXrlxh2rRpQMZpE1IsWccmygXgk08+AWD+/PncvHlTcRrh5ORk/jOZMmUK9+/fV5xIiH/3xRdfkJiYyGuvvUazZs1Ux7FrNlMuDRo0oFKlSiQkJDBjxgzVcQTQtm1bihYtys2bN/nqq69UxxHiiU6fPm3+ezp+/Hg5Xj+L2Uy5GAwG8/lWM2fOJD4+XnEi4eLiwtChQ4GM3TfJycmKEwnxeCNGjCA9PZ0mTZrI8fpWYDPlAtCiRQsCAwO5e/cu8+bNUx1HkPGAt4IFC3LlyhUWLVqkOo4Qj7R//35WrlyJwWCQk72txKbKxcnJyfyd8pQpU0hKSlKcSLi7uzNo0CAgY6ohLS1NcSIhHmZaH2zfvr08s8VKbGIr8oNSU1MpUaIEly5dYu7cuXz88ceqIzm8hIQEihQpwo0bN1i8eDEdO3ZUHUkIs61bt/Lmm2/i6urKyZMnKVq0qOpIDsGmRi4Arq6uDBw4EICJEyfKd8o64OnpSf/+/YGM7Z1Go1FxIiEyaJpmnu3o3r27FIsV2dzIBTJ/p7x06VLzM96FOnFxcQQEBHD37l2+//57Oa9J6ILpZt8cOXJw9uxZ8ufPrzqSw7C5kQtkfKfcr18/IOM4fvlOWb2cOXOaH089ZswYeTy1UC4tLY3hw4cDMGDAACkWK7PJkQtAbGwshQsXJi4ujjVr1vDOO++ojuTwbt26RUBAAPfv32fdunU0adJEdSThwBYsWEC3bt3Imzcv586dw8vLS3Ukh2KTIxeAXLly0bNnTyBjnt9GO9Ku+Pj40L17dwC+/PJL+TMRyiQkJDBq1Cgg4/4WKRbrs9mRC0BMTAwBAQEkJSWxdetW6tWrpzqSw7t27RpFihQhOTmZtWvXyhEbQokJEyYwdOhQihQpwokTJ+RhYArY7MgFIH/+/Hz00UdAxlMr7969qzaQwNfX1zyiDA4O5sKFC2oDCYdz584d84PARo8eLcWiiE2PXAAuXbpEuXLliIuLo1SpUqxfv162GyqWlJRE7dq12bdvH5UqVWLHjh14eHiojiUcxNChQ5kwYQJly5YlIiJCTj5WxKZHLgCFCxfmjz/+oGDBghw/fpxq1aqxe/du1bEcWrZs2Vi1ahU+Pj4cOHCAnj17yvqLsIro6GjzA+zGjRsnxaKQzZcLQPny5dmzZw8VK1bkxo0b1K1bl1WrVqmO5dACAgJYsWIFTk5OLFy4UE5NFlYxatQokpKSqFWrluxWVMzmp8UedO/ePdq0acP69euBjDv4Bw4cKEdrKzRu3DiGDRuGm5sb4eHhVK1aVXUkYadOnjxJmTJlSE9PZ8eOHdSsWVN1JIdmFyMXkxw5cvDTTz+Zb+YbPHgwH3/8MampqYqTOa6hQ4fSvHlzUlJSaNWqFTdu3FAdSdgp05H6zZo1k2LRAbsauTxoxowZhISEoGkaDRo0YOXKlfKcd0ViY2OpWrUqp06don79+mzcuBEXFxfVsYQd2bt3L1WrVsVgMBAZGUnZsmVVR3J4djVyeVCfPn1Ys2YNnp6ebN68mVq1anHp0iXVsRxSrly5WL16NZ6enmzdupWRI0eqjiTsjOlI/Y4dO0qx6ITdjlxM9u/fT7Nmzbh69Sq+vr6sW7eOypUrq47lkFasWEHbtm0BWL16NS1atFCcSNiDLVu20KBBA9zc3Dh16hQBAQGqIwnseORiUrlyZfbs2UO5cuW4du0aderU4aefflIdyyG1adOGkJAQIOMJlidPnlQbSNg8o9FoPlK/R48eUiw6YvcjF5O4uDhat27Npk2bMBgM1K9fHycnJzRNw2g0omnaM/3w8vJiy5Ytqj8tm5Oamkr9+vUJDw+ndOnS7Nmzhxw5cqiOJWzUd999R5s2bfDy8uLs2bPky5dPdSTxPw5TLpBxBHevXr2YP3/+C79X7ty5uX37tgVSOZ5r165RqVIlrl69SuvWrVmxYoVsFxfPLDU1ldKlS3PmzBlGjRrFp59+qjqSeIBDlQtkPJlu+/btXLp0CYPB8Fw/nJyccHNzo1GjRqo/HZu1c+dO3njjDdLS0pgyZYr5+TxCPK158+bRvXt38uXLx7lz52QErDMOVy5CP2bOnEmfPn1wdnZm69atvP7666ojCRtx//59SpQowbVr15gxY4b53jahH1IuQhlN0+jYsSPLli0jf/78HDhwgIIFC6qOJXRO0zRCQkKYMWMGRYsW5cSJE7i5uamOJf7B7neLCf0yGAzMnz+fcuXKERMTQ+vWrUlJSVEdS+jcqFGjmDFjBgD/93//J8WiU1IuQqns2bOzevVqcuXKxa5duxgwYIDqSELHJk2aZH7C5PTp02nZsqXiROJxpFyEciVKlGDJkiUAzJo1i6VLlypOJPRozpw5DB48GMh4tHmfPn0UJxJPIuUidKFZs2aMGDECgP/+978cOnRIcSKhJ2FhYeYnnA4bNsx83IvQL1nQF7qRnp5OkyZN2LRpE8WKFWPfvn3kzp1bdSyh2HfffUe7du0wGo307duXqVOnyn1RNkDKRejKrVu3qFKlChcuXKBp06b89NNPODnJANtR/fzzz7Rs2ZK0tDQ++ugjFixYIMViI+RfrdAVHx8ffvjhB9zd3Vm3bh1jxoxRHUko8uuvv9KqVSvS0tJo164d8+bNk2KxITJyEbq0cOFCPvzwQwwGAxs2bJDTEBzMjh07aNiwIQkJCbRo0YKVK1fKM4BsjJSL0K1u3bqxYMECcufOzf79+ylatKjqSMIK9u7dS/369YmPj6dRo0asWbMGd3d31bHEM5JyEbqVnJxM7dq12bt3LxUrVmTnzp14eHiojiWyUGRkJG+88QZ37tzhjTfeYMOGDfJnbqNkzUXolru7Oz/88AN58+bl4MGD9OjRA/leyH6dPHmSt956izt37lC9enXWrl0rxWLDpFyErhUqVIgVK1bg5OREWFgYCxYsUB1JZIHz589Tv359YmJiqFChAr/88gteXl6qY4kXIOUidK9+/fqMHTsWgN69e7Nnzx7FiYQlRUdHU79+faKjoyldujSbN2/G29tbdSzxgmTNRdgETdN49913+fHHH/H392f//v3kz59fdSzxgmJiYnj99dc5ceIExYsX548//sDPz091LGEBUi7CZsTFxfHqq69y6tQp6taty+bNm2V7qg27ffs2devWJTIykkKFChEeHk5AQIDqWMJCZFpM2IycOXPy448/kj17dn7//XeGDx+uOpJ4TnFxcTRq1IjIyEh8fX3ZunWrFIudkXIRNqV06dJ88803AEycOJEpU6YoTiSeVVRUFE2bNmXv3r34+PiwZcsWXn75ZdWxhIVJuQib07p1az777DMABgwYwKRJkxQnEv8mISGB5cuX07BhQwoXLkx4eDg5c+Zk06ZNlC1bVnU8kQVkwlrYJFO5jBo1isGDB5OWlibHsOuMpmns2rWLsLAwVq5cSVxcnPnnateuzZQpU6hcubLChCIryYK+sGmjR482F80XX3xhfiaMUOfSpUssXryYRYsWcebMGfPHixQpQufOnenUqRPFihVTmFBYg5SLsHljx441L+5//vnn5rIR1nP//n1Wr15NWFgYv//+u/kkhezZs/Pee+8RHBxM7dq15fEJDkTKRdiFCRMmMHToUABGjhzJqFGj5Hj2LGY0GgkPD2fRokV8//333Lt3z/xzdevWJTg4mJYtW5IjRw6FKYUqUi7CbkyePJmBAwcCGY/C/fLLL6VgssD58+fN017nz583f7x48eJ07tyZjh07UqRIEXUBhS5IuQi7Mm3aNPr16wfA4MGDGT9+vBSMBcTHx7Nq1SoWLVrE9u3bzR/38vKidevWBAcHU7NmTfm9FmZSLsLuzJw5kz59+gB/b1WWL3rPzmg0sm3bNsLCwvjhhx9ISEgAwGAw8Oabb9K5c2datGiBp6en4qRCj6RchF2aM2cOPXv2BKBv375MnTpVCuYpnTlzhkWLFrF48WIuXbpk/njJkiUJDg6mQ4cOFCpUSGFCYQukXITdWrBgAd26dQMynmo5adIkOcb9MWJjY/n+++8JCwtj586d5o/nypWLNm3aEBwcTLVq1aSgxVOTchF27euvv6Zr165omkaePHno378/vXv3JmfOnKqjKZeens5vv/1GWFgYP/74I4mJiQA4OTnRoEEDgoODefvtt+WBXeK5SLkIu/fTTz8xePBgTp06BUDu3Lnp168fffr0IVeuXIrTWd/JkyfN017R0dHmj5cqVco87SXH3osXJeUiHEJ6ejorVqzgiy++4OTJkwB4e3sTEhJC37597f7hVHfv3uW7774jLCyM3bt3mz+eO3du2rZtS3BwMFWqVJFpL2ExUi7CoaSnp7Ny5Uq++OILjh8/DmSsK4SEhBASEmJXJZOWlsaWLVtYtGgRa9asITk5GQBnZ2caNWpEcHAwzZo1w93dXXFSYY+kXIRDSk9PZ9WqVYwePZpjx44BGc+L6du3LyEhIeTJk0dxwud37NgxFi1axJIlS7h69ar542XLliU4OJj27dvj6+urMKFwBFIuwqEZjUZ++OEHRo8ezZEjR4CMGwP79OlDv3798PHxUZzw6dy+fZtvv/2WRYsWsXfvXvPHfXx8aNeuHcHBwVSsWFGmvYTVSLkIQUbJ/Pjjj4waNYrDhw8DkCNHDnr37k3//v3Jmzev4oQPS01NZdOmTYSFhfHzzz+TkpICgIuLC02aNKFz5840adIENzc3xUmFI5JyEeIBRqORNWvWMHr0aA4dOgRklEyvXr0YMGCALkomMjKSRYsWsXTpUmJiYswfr1ChAsHBwbRt25b8+fMrTCiElIsQj2Q0Glm7di2jRo0iIiICyDg+vnv37jRr1oygoCCrLv7fvHmT5cuXExYWxsGDB80fz5cvHx06dKBz586UL1/eanmE+DdSLkI8gaZp/Pzzz4waNYoDBw5k+rkiRYpQoUIFypcvb/5vkSJFLLaukZKSwi+//EJYWBjr1q0jLS0NAFdXV5o1a0ZwcDCNGjXC1dXVItcTwpKkXIR4CpqmsX79ekJDQzl48GCmM7celCtXLsqXL5+pcMqUKUO2bNme+joREREsWrSIZcuWcfPmTfPPVa5cmeDgYNq0aaOL6TkhnkTKRYjncPv2bSIjI4mIiODQoUNERERw9OhRUlNTH3qts7MzpUqVMheOqXTy5ctnfs3169dZtmwZixYtIjIy0vxxX19f87RX2bJlrfK5CWEJUi5CWEhKSgonTpzIVDgRERHcvn37ka/38/OjfPnyGAwGNm3aRHp6OgBubm688847BAcH06BBA1xcXKz5aQhhEVIuQmQhTdOIjo42F42pdM6cOfPQa6tWrUpwcDDvv/++Td/EKQRIuQihRHx8PIcPH+bQoUPcvXuX5s2bU6pUKdWxhLAYKRchhBAW56Q6gBBCCPsj5SKEEMLipFyEEEJYnJSLEEIIi5NyEUIIYXFSLkIIISxOykUIIYTFSbkIIYSwOCkXIYQQFiflIoQQwuKkXIQQQliclIsQQgiLk3IRQghhcVIuQgghLE7KRQghhMVJuQghhLA4KRchhBAWJ+UihBDC4qRchBBCWJyUixBCCIuTchFCCGFxUi5CCCEsTspFCCGExUm5CCGEsDgpFyGEEBb3/0ZO3t+0/QuGAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def calculate_mean_latent_vectors(input_dir, output_file=None):\n",
        "    \"\"\"\n",
        "    Load latent vectors from JSON files and calculate the mean vector for each class.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Directory containing the JSON files with latent vectors\n",
        "        output_file (str, optional): File path to save the mean vectors. If None, only returns the dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with class names as keys and mean latent vectors as values\n",
        "    \"\"\"\n",
        "    # Dictionary to store the mean latent vectors\n",
        "    mean_latent_vectors = {}\n",
        "\n",
        "    # Find all JSON files in the input directory\n",
        "    json_files = list(Path(input_dir).glob(\"*_latent_vectors.json\"))\n",
        "    if not json_files:\n",
        "        print(f\"No latent vector JSON files found in {input_dir}\")\n",
        "\n",
        "        # Try looking for a combined file\n",
        "        combined_file = Path(input_dir) / \"all_classes_latent_vectors.json\"\n",
        "        if combined_file.exists():\n",
        "            json_files = [combined_file]\n",
        "            print(f\"Found combined file: {combined_file}\")\n",
        "        else:\n",
        "            return mean_latent_vectors\n",
        "\n",
        "    print(f\"Found {len(json_files)} JSON files to process\")\n",
        "\n",
        "    # Process each JSON file\n",
        "    for json_file in json_files:\n",
        "        print(f\"Processing file: {json_file}\")\n",
        "\n",
        "        with open(json_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Handle both separate and combined file formats\n",
        "        if len(data.keys()) == 1 and json_file.name != \"all_classes_latent_vectors.json\":\n",
        "            # Single class file format\n",
        "            class_name = list(data.keys())[0]\n",
        "            latent_vectors = np.array(data[class_name])\n",
        "\n",
        "            if len(latent_vectors) > 0:\n",
        "                # Calculate the mean vector for this class\n",
        "                mean_vector = np.mean(latent_vectors, axis=0)\n",
        "                mean_latent_vectors[class_name] = mean_vector.tolist()\n",
        "                print(f\"Calculated mean vector for {class_name} from {len(latent_vectors)} samples\")\n",
        "        else:\n",
        "            # Combined file format or all_classes file\n",
        "            for class_name, latent_vectors in data.items():\n",
        "                latent_vectors = np.array(latent_vectors)\n",
        "\n",
        "                if len(latent_vectors) > 0:\n",
        "                    # Calculate the mean vector for this class\n",
        "                    mean_vector = np.mean(latent_vectors, axis=0)\n",
        "                    mean_latent_vectors[class_name] = mean_vector.tolist()\n",
        "                    print(f\"Calculated mean vector for {class_name} from {len(latent_vectors)} samples\")\n",
        "\n",
        "    print(f\"Calculated mean latent vectors for {len(mean_latent_vectors)} classes\")\n",
        "\n",
        "    # Save the mean vectors to a JSON file if requested\n",
        "    if output_file and mean_latent_vectors:\n",
        "        os.makedirs(os.path.dirname(os.path.abspath(output_file)), exist_ok=True)\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(mean_latent_vectors, f)\n",
        "        print(f\"Saved mean latent vectors to {output_file}\")\n",
        "\n",
        "    return mean_latent_vectors\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "input_dir = \"latent_vectors\"  # Directory containing JSON files with latent vectors\n",
        "# output_file = \"path/to/mean_latent_vectors.json\"  # Where to save the mean vectors\n",
        "\n",
        "# Calculate and save mean latent vectors\n",
        "mean_vectors = calculate_mean_latent_vectors(input_dir)\n",
        "\n",
        "# # You can now use mean_vectors dictionary for further processing\n",
        "# # Example: Access the mean vector for a specific class\n",
        "# if \"banana\" in mean_vectors:\n",
        "#     cat_mean_vector = mean_vectors[\"banana\"]\n",
        "#     print(cat_mean_vector)\n",
        "#     print(f\"Mean vector for 'banana' has length: {len(cat_mean_vector)}\")\n",
        "\n",
        "# print(mean_vectors.keys())\n",
        "\n",
        "z_cat = mean_vectors['cat']\n",
        "z_cat = torch.tensor(z_cat, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "sequence_cat, penstate_cat = sample_from_z(model, z_cat, T=1)\n",
        "penstate_cat = penstate_cat.unsqueeze(-1)  # Expand the dimension of penstate  # Sample from model\n",
        "# concatenate penstate to sample_sketch\n",
        "sample_sketch_cat = torch.cat((sequence_cat, penstate_cat), dim=-1)  # [1, max_len, 5]\n",
        "sample_sketch_cat = convert_to_5d(sample_sketch_cat)  # Convert to 5D format\n",
        "sample_sketch_cat = sample_sketch_cat.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "# visualize\n",
        "strokes = visualize_delta_drawing(sample_sketch_cat.cpu().numpy())\n",
        "\n",
        "z_car = mean_vectors['car']\n",
        "z_car = torch.tensor(z_car, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "sequence_car, penstate_car = sample_from_z(model, z_car, T=1)\n",
        "penstate_car = penstate_car.unsqueeze(-1)  # Expand the dimension of penstate\n",
        "sample_sketch_car = torch.cat((sequence_car, penstate_car), dim=-1)  # [1, max_len, 5]\n",
        "sample_sketch_car = convert_to_5d(sample_sketch_car)  # Convert to 5D format\n",
        "sample_sketch_car = sample_sketch_car.squeeze(0)  # Remove batch dimension\n",
        "\n",
        "# visualize\n",
        "strokes_car = visualize_delta_drawing(sample_sketch_car.cpu().numpy())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}